{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595a5d18",
   "metadata": {},
   "source": [
    "AI Agent: Textbook to Notebook Notes Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f755b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "import textwrap\n",
    "import asyncio\n",
    "try:\n",
    "    import fitz  # PyMuPDF\n",
    "except Exception:\n",
    "    fitz = None\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "from fpdf import FPDF\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30aa8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41871c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üîç API Configuration Check ===\n",
      " OpenAI API Key Loaded: sk-proj-****\n",
      " Google API Key Loaded: AIzaSyDn****\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "print(\"\\n=== üîç API Configuration Check ===\")\n",
    "if openai_api_key:\n",
    "    print(f\" OpenAI API Key Loaded: {openai_api_key[:8]}****\")\n",
    "else:\n",
    "    print(\" Missing OpenAI API Key. Please set it in .env\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\" Google API Key Loaded: {google_api_key[:8]}****\")\n",
    "else:\n",
    "    print(\" Missing Google API Key. Please set it in .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4e81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "gemini_client = AsyncOpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07755414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n",
    "    clarity_score: int\n",
    "    accuracy_score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af29cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 3000, overlap: int = 300):\n",
    "    \"\"\"Split extracted text into overlapping chunks suitable for LLMs.\n",
    "\n",
    "    - max_chars: rough upper bound per chunk to keep prompts manageable\n",
    "    - overlap: carry some context to the next chunk to preserve continuity\n",
    "    \"\"\"\n",
    "    text = text or \"\"\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "\n",
    "    for para in paragraphs:\n",
    "        if len(current) + len(para) + 2 <= max_chars:\n",
    "            current = (current + \"\\n\\n\" + para) if current else para\n",
    "        else:\n",
    "            if current:\n",
    "                chunks.append(current)\n",
    "            # if a single paragraph is too large, hard-split it\n",
    "            if len(para) > max_chars:\n",
    "                start = 0\n",
    "                while start < len(para):\n",
    "                    end = min(start + max_chars, len(para))\n",
    "                    chunks.append(para[start:end])\n",
    "                    start = max(0, end - overlap)\n",
    "                current = \"\"\n",
    "            else:\n",
    "                current = para\n",
    "\n",
    "    if current:\n",
    "        chunks.append(current)\n",
    "\n",
    "    # add overlap between chunks\n",
    "    if overlap > 0 and len(chunks) > 1:\n",
    "        overlapped = []\n",
    "        for i, ch in enumerate(chunks):\n",
    "            if i == 0:\n",
    "                overlapped.append(ch)\n",
    "            else:\n",
    "                prev = overlapped[-1]\n",
    "                tail = prev[-overlap:]\n",
    "                overlapped.append(tail + ch if tail else ch)\n",
    "        return overlapped\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5273ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_notes(text_chunk: str, retries=2, feedback=\"\"):\n",
    "    \"\"\"Generate structured notes for a given text chunk using Ollama model.\"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are an AI Developer Agent specialized in academic note generation. \"\n",
    "        \"Analyze the input text and produce structured, markdown-formatted notes. \"\n",
    "        \"Highlight key ideas, maintain precision, and ensure clarity. \"\n",
    "        \"Use professional, educational tone suitable for developers or researchers.\"\n",
    "    )\n",
    "\n",
    "    if feedback:\n",
    "        user_prompt = f\"Refine the previous output using this feedback:\\n{feedback}\\n\\nOriginal Text:\\n{text_chunk}\"\n",
    "    else:\n",
    "        user_prompt = f\"Generate professional academic notes for:\\n{text_chunk}\"\n",
    "\n",
    "    try:\n",
    "        response = await ollama_client.chat.completions.create(\n",
    "            model=\"llama3:8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "        )\n",
    "        notes = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Ollama generation error: {e}\")\n",
    "        return f\"Error generating notes: {e}\"\n",
    "\n",
    "    if retries > 0:\n",
    "        evaluation = await evaluate_notes(text_chunk, notes)\n",
    "        if not evaluation.is_acceptable or (evaluation.clarity_score < 3 or evaluation.accuracy_score < 3):\n",
    "            print(f\"üîÅ Re-evaluating due to low quality: {evaluation.feedback}\")\n",
    "            return await generate_notes(text_chunk, retries - 1, evaluation.feedback)\n",
    "        else:\n",
    "            print(\"‚úÖ Evaluation passed.\")\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c956eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_notes(text_chunk: str, notes: str) -> Evaluation:\n",
    "    \"\"\"Evaluate generated notes with Gemini for accuracy and clarity.\"\"\"\n",
    "    prompt = (\n",
    "        \"Evaluate these notes based on accuracy, clarity, and completeness. \"\n",
    "        \"Return a JSON with: is_acceptable (bool), feedback (string), clarity_score (1‚Äì5), accuracy_score (1‚Äì5). \"\n",
    "        f\"\\n\\n--- Original Text ---\\n{text_chunk}\\n\\n--- Notes ---\\n{notes}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = await gemini_client.chat.completions.create(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        return Evaluation(**data)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gemini evaluation error: {e}\")\n",
    "        # FIXED\n",
    "    return Evaluation(\n",
    "        is_acceptable=True,\n",
    "        feedback=f\"Fallback: {e}\",\n",
    "        clarity_score=5,\n",
    "        accuracy_score=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81654b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_final_summary(all_notes: str):\n",
    "    \"\"\"Generate a concise, professional executive summary.\"\"\"\n",
    "    print(\"üß† Generating executive summary...\")\n",
    "    prompt = (\n",
    "        \"Summarize all provided notes into a clean, professional overview in Markdown. \"\n",
    "        \"Focus on major themes, concepts, and takeaways suitable for AI developers or educators.\\n\\n\"\n",
    "        f\"{all_notes}\"\n",
    "    )\n",
    "    try:\n",
    "        response = await gemini_client.chat.completions.create(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gemini summary error: {e}\")\n",
    "        return \"Error generating summary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767f08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyledPDF(FPDF):\n",
    "    \"\"\"Stylish PDF generator for developer-grade reports.\"\"\"\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.set_text_color(100, 100, 100)\n",
    "        self.cell(0, 10, 'AI Agent Developer Notes Generator', 0, 0, 'C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.set_text_color(128, 128, 128)\n",
    "        page_num_text = f\"Page {self.page_no()} | AI Agent Developer\"\n",
    "        self.cell(0, 10, page_num_text.encode('latin-1', 'replace').decode('latin-1'), 0, 0, 'C')\n",
    "\n",
    "    def set_title_page(self, title: str, subtitle: str = \"\"):\n",
    "        self.add_page()\n",
    "        self.set_font('Arial', 'B', 22)\n",
    "        self.set_text_color(0, 51, 102)\n",
    "        # Apply encoding fix\n",
    "        safe_title = title.encode('latin-1', 'replace').decode('latin-1')\n",
    "        self.cell(0, 15, safe_title, 0, 1, 'C')\n",
    "        if subtitle:\n",
    "            self.ln(4)\n",
    "            self.set_font('Arial', '', 12)\n",
    "            self.set_text_color(80, 80, 80)\n",
    "            # Apply encoding fix\n",
    "            safe_subtitle = subtitle.encode('latin-1', 'replace').decode('latin-1')\n",
    "            self.cell(0, 10, safe_subtitle, 0, 1, 'C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def add_table_of_contents(self, sections):\n",
    "        if not sections:\n",
    "            return\n",
    "        self.add_page()\n",
    "        self.set_font('Arial', 'B', 16)\n",
    "        self.set_text_color(51, 102, 153)\n",
    "        self.cell(0, 10, 'Table of Contents', 0, 1)\n",
    "        self.ln(2)\n",
    "        self.set_font('Arial', '', 11)\n",
    "        self.set_text_color(0, 0, 0)\n",
    "        for idx, sec in enumerate(sections, start=1):\n",
    "            title = sec.get('title', f'Section {idx}')\n",
    "            # Apply encoding fix\n",
    "            toc_entry = f\"{idx}. {title}\".encode('latin-1', 'replace').decode('latin-1')\n",
    "            self.multi_cell(0, 6, toc_entry)\n",
    "        self.ln(4)\n",
    "\n",
    "    def process_markdown_content(self, content):\n",
    "        self.set_font('Arial', '', 11)\n",
    "        for line in content.split('\\n'):\n",
    "            # Apply encoding fix to the line before processing\n",
    "            safe_line = line.encode('latin-1', 'replace').decode('latin-1')\n",
    "            \n",
    "            if line.startswith('# '):\n",
    "                self.ln(8)\n",
    "                self.set_font('Arial', 'B', 16)\n",
    "                self.set_text_color(0, 51, 102)\n",
    "                self.cell(0, 10, safe_line[2:], 0, 1)\n",
    "            elif line.startswith('## '):\n",
    "                self.ln(6)\n",
    "                self.set_font('Arial', 'B', 13)\n",
    "                self.set_text_color(51, 102, 153)\n",
    "                self.cell(0, 8, safe_line[3:], 0, 1)\n",
    "            else:\n",
    "                self.set_font('Arial', '', 11)\n",
    "                self.set_text_color(0, 0, 0)\n",
    "                self.multi_cell(0, 6, safe_line)\n",
    "                self.ln(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6b7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_styled_pdf_file(notes_markdown: str, source_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a beautifully formatted PDF with enhanced styling.\n",
    "    \"\"\"\n",
    "    title = os.path.splitext(os.path.basename(source_filename))[0].replace('_', ' ').title()\n",
    "    output_filename = f\"{os.path.splitext(source_filename)[0]}_styled_notes.pdf\"\n",
    "    output_filename_abs = os.path.abspath(output_filename)\n",
    "    \n",
    "    # Create styled PDF instance\n",
    "    pdf = StyledPDF()\n",
    "    \n",
    "    # Set up document properties\n",
    "    pdf.set_title(\"AI Generated Textbook Notes\")\n",
    "    \n",
    "    # Create title page\n",
    "    pdf.set_title_page(\n",
    "        title=title,\n",
    "        subtitle=\"Generated by AI Textbook Notes Generator\"\n",
    "    )\n",
    "    \n",
    "    # Parse content to extract sections for table of contents\n",
    "    sections = []\n",
    "    lines = notes_markdown.split('\\n')\n",
    "    current_section = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('# '):\n",
    "            if current_section:\n",
    "                sections.append(current_section)\n",
    "            current_section = {'title': line[2:].strip()}\n",
    "        elif line.startswith('## ') and current_section:\n",
    "            current_section['title'] = line[3:].strip()\n",
    "    \n",
    "    if current_section:\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    # Add table of contents\n",
    "    pdf.add_table_of_contents(sections)\n",
    "    \n",
    "    # Process and add content\n",
    "    try:\n",
    "        pdf.process_markdown_content(notes_markdown)\n",
    "        \n",
    "        # Save the PDF\n",
    "        pdf.output(output_filename_abs)\n",
    "        print(f\"‚ú® Beautiful PDF created successfully: {output_filename_abs}\")\n",
    "        return output_filename_abs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating styled PDF: {e}\")\n",
    "        \n",
    "        # Fallback: Create error report with same styling\n",
    "        try:\n",
    "            error_pdf = StyledPDF()\n",
    "            error_pdf.add_page()\n",
    "            \n",
    "            # Error title page\n",
    "            error_pdf.set_title_page(\n",
    "                title=\"Error Report\",\n",
    "                subtitle=\"PDF Generation Failed\"\n",
    "            )\n",
    "            \n",
    "            # Error details\n",
    "            error_section = \"Error Details\\n\\n\" + str(e)\n",
    "            error_pdf.process_markdown_content(error_section)\n",
    "            \n",
    "            error_pdf.output(output_filename_abs)\n",
    "            print(f\"Error report saved: {output_filename_abs}\")\n",
    "            return output_filename_abs\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"CRITICAL: Failed to create error report: {e2}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f509c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_textbook(file, progress=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Enhanced main orchestrator function with better progress tracking.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return None\n",
    "\n",
    "    if not 'PYMUPDF_OK' in globals() or not PYMUPDF_OK:\n",
    "        print(\"‚ùå PyMuPDF not available. Please install 'PyMuPDF' and restart the kernel.\")\n",
    "        return None\n",
    "\n",
    "    pdf_file_path = file.name\n",
    "    \n",
    "    # STEP 1: Extract Text with PyMuPDF (fitz)\n",
    "    print(\"Step 1/5: Extracting Text...\")\n",
    "    progress(0, desc=\"Step 1/5: Extracting Text...\")\n",
    "    full_text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_file_path)\n",
    "        num_pages = len(doc)\n",
    "        for i, page in enumerate(doc):\n",
    "            progress((i + 1) / num_pages, desc=f\"Extracting from Page {i + 1}/{num_pages}\")\n",
    "            full_text += page.get_text() + \"\\n\"\n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text with PyMuPDF: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not full_text.strip():\n",
    "        print(\"No text could be extracted from the PDF.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"‚úÖ Text extraction complete. Total characters: {len(full_text)}\")\n",
    "    \n",
    "    # STEP 2: Chunk Text\n",
    "    chunks = chunk_text(full_text)\n",
    "    num_chunks = len(chunks)\n",
    "    all_notes = []\n",
    "    \n",
    "    # STEP 3: Generate Notes\n",
    "    print(f\"Step 2/5: Generating notes from {num_chunks} text chunks...\")\n",
    "    progress(0, desc=\"Step 2/5: Generating Notes...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        progress((i + 1) / num_chunks, desc=f\"Processing Chunk {i + 1}/{num_chunks}\")\n",
    "        notes_chunk = await generate_notes(chunk)\n",
    "        all_notes.append(notes_chunk)\n",
    "        \n",
    "    combined_notes = \"\\n\\n---\\n\\n\".join(all_notes)\n",
    "    print(\"‚úÖ Notes generation complete\")\n",
    "\n",
    "    # STEP 4: Generate Final Summary\n",
    "    print(\"Step 3/5: Generating Final Summary...\")\n",
    "    progress(0.8, desc=\"Step 3/5: Generating Final Summary...\")\n",
    "    final_summary = await generate_final_summary(combined_notes)\n",
    "    print(\"‚úÖ Summary generation complete\")\n",
    "    \n",
    "    final_markdown = f\"# Executive Summary\\n\\n{final_summary}\\n\\n---\\n\\n# Detailed Notes\\n\\n{combined_notes}\"\n",
    "\n",
    "    # STEP 5: Create Styled PDF\n",
    "    print(\"Step 4/5: Creating Beautiful PDF...\")\n",
    "    progress(0.9, desc=\"Step 4/5: Creating Beautiful PDF...\")\n",
    "    pdf_path = create_styled_pdf_file(final_markdown, pdf_file_path)\n",
    "    \n",
    "    progress(1.0, desc=\"Step 5/5: Complete!\")\n",
    "    print(\"üéâ All processing complete!\")\n",
    "    \n",
    "    return pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399ef01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_notes_interface(file, progress=gr.Progress(track_tqdm=True)):\n",
    "    \"\"\"Enhanced interface function with better feedback\"\"\"\n",
    "    if file is not None:\n",
    "        try:\n",
    "            result = await process_textbook(file, progress)\n",
    "            if result:\n",
    "                return result\n",
    "            else:\n",
    "                # Return None to File output when processing fails\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            # Return None to avoid File component stat on error strings\n",
    "            print(f\"‚ùå An error occurred: {str(e)}\")\n",
    "            return None\n",
    "    # No file uploaded; return None for File output\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9564fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correct PyMuPDF detected! Using: PyMuPDF 1.26.5: Python bindings for the MuPDF 1.26.10 library (rebased implementation).\n"
     ]
    }
   ],
   "source": [
    "# --- Safe PyMuPDF Import Check ---\n",
    "PYMUPDF_OK = False\n",
    "try:\n",
    "    if fitz is None or not hasattr(fitz, \"open\"):\n",
    "        raise ImportError(\n",
    "            \"\\n‚ùå Wrong 'fitz' module detected or not installed.\\n\"\n",
    "            \"Please run inside your virtual environment:\\n\"\n",
    "            \"   pip uninstall fitz -y\\n\"\n",
    "            \"   pip install PyMuPDF\\n\"\n",
    "        )\n",
    "    PYMUPDF_OK = True\n",
    "    print(\"‚úÖ Correct PyMuPDF detected! Using:\", getattr(fitz, \"__doc__\", \"PyMuPDF\").splitlines()[0])\n",
    "except ImportError as e:\n",
    "    # Warn but do not exit; allow UI to load so user can fix env and retry\n",
    "    print(e)\n",
    "# --------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76da59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching AI Agent Developer Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/5: Extracting Text...\n",
      "‚úÖ Text extraction complete. Total characters: 48832\n",
      "Step 2/5: Generating notes from 24 text chunks...\n",
      "üîÅ Re-evaluating due to low quality: The notes are very clear and easy to understand, providing good summaries of the content. However, there is a significant accuracy issue regarding the preface: the notes state \"No preface provided in this edition,\" while the original text's Table of Contents clearly lists \"Preface to the Expanded and Updated Edition.\" Additionally, while all chapters are mentioned, the notes do not consistently list each individual chapter as a distinct heading or bullet point, particularly within Step I, II, and III (e.g., 'Cautions and Comparisons,' 'The Low-Information Diet,' 'Outsourcing Life' are summarized within broader sections rather than given their own distinct entries as they appear in the original TOC). This affects the completeness and precision of the outline.\n",
      "üîÅ Re-evaluating due to low quality: The notes are excellent in terms of accuracy and clarity of the book's structure and chapter titles, perfectly mirroring the table of contents provided in the original text. The markdown formatting is clean, logical, and easy to read. However, the notes are severely incomplete as they lack any actual content or summaries for the chapters. Almost every section contains a placeholder like `[Insert summary]` or states 'No information provided,' which means the core informational value of the notes is missing. The final 'Contents' section with `[Insert Table of Contents]` is redundant given that the entire output essentially *is* a structured table of contents.\n",
      "üîÅ Re-evaluating due to low quality: The notes accurately summarize the preface and correctly list several specific chapters and bonus materials with their page numbers. However, they suffer from significant incompleteness and structural issues. Major sections like 'The Best of the Blog,' 'Living the 4-Hour Workweek: Case Studies, Tips, and Hacks,' and the entirety of 'Step I' and 'Step II' are completely omitted. The notes also incorrectly categorize 'Restricted Reading' as part of 'Bonus Materials,' when they are distinct sections in the original text. Additionally, the presentation of chapters under 'Step III' and 'Step IV' is somewhat unclear; the main step heading includes a page number (presumably for the first chapter of that step), but then subsequent bullet points list later chapters, leaving the initial chapter's content undetailed.\n",
      "üîÅ Re-evaluating due to low quality: The notes provide a good structural overview for the preface and accurately list many of the main chapter headings and their corresponding page numbers for Steps III, IV, and the Bonus Material. However, there are significant omissions, including the entire 'THE BEST OF THE BLOG' section and the 'PROPOSAL TO WORK REMOTELY ON A CONTRACT BASIS' entry. The 'LIVING THE 4-HOUR WORKWEEK' section also fails to list the individual case studies present in the original text, opting for a generic description. Additionally, there's a minor structural error with 'Liberation' being incorrectly placed under 'Step III', and the page range given for 'LIVING THE 4-HOUR WORKWEEK' is slightly inaccurate. The description for 'RESTRICTED READING' is an interpretation rather than content-specific information from the provided source.\n",
      "üîÅ Re-evaluating due to low quality: The notes demonstrate excellent clarity and organization, using clear headings and concise language to present information effectively. However, the accuracy and completeness are significantly impacted by the omission of the initial narrative section of the original text, where the author describes the experience of hitting the New York Times bestseller list. While the notes accurately summarize the details regarding the book's success, the global impact of lifestyle design, and the specifics of the new expanded edition, they fail to provide a comprehensive overview of the entire provided source material. A minor inaccuracy also exists in attributing the 'creation of new knowledge, resources, and success stories' to the general 'expansion and evolution' rather than specifically to the new content within the expanded edition.\n",
      "‚úÖ Evaluation passed.\n",
      "üîÅ Re-evaluating due to low quality: The notes demonstrate strong clarity and organization, effectively summarizing the core reasons for the book's major overhaul and its continued relevance in economic downturns. The breakdown of significant events, shifts in priorities, and the 'Yes and yes' answer to the book's continued applicability are accurately captured from the provided text.\n",
      "\n",
      "However, the notes are significantly incomplete. The entire section discussing the 'Experiments in Lifestyle Design blog'‚Äîits launch, rapid success, role as a 'laboratory' for readers, and its connection to the book's 'Best of the Blog' section‚Äîis entirely absent. This omission accounts for a substantial portion of the original text and significantly impacts the completeness of the evaluation. Additionally, some points, such as relating 'Options C and D' to 'time management' and 'selling services online,' are reasonable interpretations but are not explicitly stated in the original text, leading to minor inaccuracies.\n",
      "‚úÖ Evaluation passed.\n",
      "üîÅ Re-evaluating due to low quality: The notes are generally clear and well-structured, effectively summarizing the core arguments about lifestyle design, financial redistribution, and the opportunities presented during economic downturns. The use of headings like 'Key Idea 1' and 'Key Idea 2' aids readability.\n",
      "\n",
      "However, there are significant issues regarding accuracy and completeness:\n",
      "1.  **Inaccuracy:** The concluding note stating 'No part of this book has been updated since its original printing in 2009' is factually incorrect. The original text explicitly states, 'I hope you enjoy this new edition,' indicating that the preface itself is for a new, updated edition, not that the book is outdated.\n",
      "2.  **Omission:** The notes miss several key examples of companies born during recessions (e.g., Monopoly, Apple, Cliff Bar, Scrabble, KFC, Domino's Pizza, FedEx, Microsoft). These examples were used in the original text to strongly support the claim that economic downturns present unique opportunities.\n",
      "3.  **Redundancy/Clarity in Note:** The note 'The introduction is written by Tim Ferriss' is redundant given that the notes already attribute the entire Preface to Tim Ferriss at the beginning.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "üîÅ Re-evaluating due to low quality: The notes demonstrate excellent clarity and are well-structured, making them easy to understand and reference. They accurately capture the core philosophy of shifting from a 'dream job' pursuit to automating income and freeing time, and correctly outline the initial steps of the DEAL framework (Definition and Elimination) as presented in the excerpt. However, there is a significant inaccuracy in the title: the original text is an excerpt from 'The 4-Hour Workweek' by Tim Ferriss, not 'The Art of Deal Making,' although 'deal making' is a central theme within it. For completeness, the notes could also include the explicit mention of how the principles apply to both employees and entrepreneurs to achieve results like doubling income or vacation time, and the reference to the 'often-forgotten Italian economist' who inspired the time-saving techniques.\n",
      "‚úÖ Evaluation passed.\n",
      "üîÅ Re-evaluating due to low quality: The notes are clearly organized and accurately summarize the core concepts of luxury lifestyle design ingredients and their implementation. However, they are incomplete, notably omitting most of Tim Ferriss's listed achievements and the Heinrich Heine quote. The application of the Niels Bohr quote is also a slight misinterpretation, directly attributing the 'expert' description to Ferriss rather than presenting it as a general definition. Additionally, the author's name, location, and date from the original text's introduction are missing, and a concluding sentence was added to the 'My Unconventional Background' section that was not present in the original snippet.\n",
      "‚úÖ Evaluation passed.\n",
      "‚úÖ Evaluation passed.\n",
      "üîÅ Re-evaluating due to low quality: The notes are well-structured, clear, and generally cover the main points of the original text. The use of headings and bullet points makes the information easy to digest.\n",
      "\n",
      "However, there is a significant accuracy issue in the 'Early Entrepreneurial Ventures' section. The notes incorrectly state that the speed-reading seminar generated '$533 in revenue (three hours x $50 per hour)'. Based on the original text ('I sell 32 spots at $50 each for the 3-hour event, and $533 per hour convinces me...'), the total revenue was 32 spots * $50/spot = $1600. The $533 was the *hourly rate* ($1600 / 3 hours), not the total revenue. This is a factual misrepresentation of a key financial detail.\n",
      "\n",
      "Additionally, while mostly complete, some vivid descriptive details from the original text were omitted (e.g., 'god-awful neon green flyers' with 'bullsh*t' written on them, the specific 'David Koresh‚Äìlike abilities' of twenty-somethings, and the primary driver for closing the speed-reading business being the author's boredom and preference for products over services, rather than just lack of interest from customers).\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css=\"\"\"\n",
    ".gradio-container {\n",
    "    max-width: 850px !important;\n",
    "    margin: auto;\n",
    "    font-family: 'Segoe UI', sans-serif;\n",
    "}\n",
    ".title {\n",
    "    text-align: center;\n",
    "    color: #003366;\n",
    "    font-size: 28px;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    ".description {\n",
    "    text-align: center;\n",
    "    color: #555;\n",
    "    margin-bottom: 25px;\n",
    "}\n",
    ".footer {\n",
    "    text-align: center;\n",
    "    color: #888;\n",
    "    font-size: 12px;\n",
    "    margin-top: 40px;\n",
    "}\n",
    "\"\"\") as iface:\n",
    "    \n",
    "    gr.HTML(\"\"\"\n",
    "    <div class=\"title\">ü§ñ AI Agent Developer: Textbook ‚Üí Notes Generator</div>\n",
    "    <div class=\"description\">\n",
    "        Built for AI developers and educators to auto-generate well-structured academic notes \n",
    "        and summaries from textbook PDFs.\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "    file_input = gr.File(label=\"üìò Upload Textbook (PDF)\", file_types=[\".pdf\"])\n",
    "    output_file = gr.File(label=\"üì• Download Generated Notes (PDF)\")\n",
    "    submit_btn = gr.Button(\"‚öôÔ∏è Generate Notes\", variant=\"primary\")\n",
    "\n",
    "    submit_btn.click(\n",
    "        fn=create_notes_interface,\n",
    "        inputs=[file_input],\n",
    "        outputs=[output_file],\n",
    "        show_progress=\"full\"\n",
    "    )\n",
    "\n",
    "    gr.HTML(\"\"\"\n",
    "    <div class=\"footer\">\n",
    "        ¬© 2025 AI Agent Developer Suite | Powered by Ollama & Gemini APIs\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Launching AI Agent Developer Interface...\")\n",
    "    iface.launch(server_name=\"127.0.0.1\", share=False, show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5c44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
