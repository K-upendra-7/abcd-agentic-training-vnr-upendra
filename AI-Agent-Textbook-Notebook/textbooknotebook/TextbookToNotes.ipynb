{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595a5d18",
   "metadata": {},
   "source": [
    "AI Agent: Textbook to Notebook Notes Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70970d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n",
      "Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3:8b\n",
    "!ollama serve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import requests\n",
    "import asyncio\n",
    "import gradio as gr\n",
    "from docx import Document\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30aa8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41871c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key found, starting with: sk-proj-...\n",
      "Google API Key found, starting with: AIzaSyDn...\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key found, starting with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please set it in your .env file.\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key found, starting with: {google_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"Google API Key not found. Please set it in your .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4e81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "gemini_client = AsyncOpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07755414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    \"\"\"Defines evaluator output.\"\"\"\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5273ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_notes(text_chunk: str, retries=2, feedback=\"\"):\n",
    "    \"\"\"\n",
    "    Generate structured notes for a given text chunk using LLaMA3:8b.\n",
    "    Auto-retries with feedback from Gemini evaluation if needed.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are an expert academic assistant. \"\n",
    "        \"Produce clear, well-structured Markdown notes summarizing key ideas, \"\n",
    "        \"definitions, and concepts from the provided text.\"\n",
    "    )\n",
    "\n",
    "    if feedback:\n",
    "        user_prompt = (\n",
    "            f\"Improve the previous notes using this feedback:\\n{feedback}\\n\\n\"\n",
    "            f\"Original text:\\n{text_chunk}\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = f\"Generate concise academic notes for the following text:\\n{text_chunk}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = await ollama_client.chat.completions.create(\n",
    "            model=\"llama3:8b\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        notes = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Ollama generation error: {e}\")\n",
    "        return f\"Error generating notes: {e}\"\n",
    "\n",
    "    if retries > 0:\n",
    "        evaluation = await evaluate_notes(text_chunk, notes)\n",
    "        if not evaluation.is_acceptable:\n",
    "            print(f\"üîÅ Retrying with feedback: {evaluation.feedback}\")\n",
    "            return await generate_notes(text_chunk, retries - 1, evaluation.feedback)\n",
    "        else:\n",
    "            print(\"‚úÖ Evaluation passed.\")\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81654b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED: Changed the model name to one compatible with the API endpoint\n",
    "async def evaluate_notes(text_chunk: str, notes: str) -> Evaluation:\n",
    "    \"\"\"\n",
    "    Evaluates generated notes using Gemini for accuracy and clarity.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are a quality evaluator. Check if the notes correctly and clearly summarize the text. \"\n",
    "        \"Respond in JSON with keys: is_acceptable (bool) and feedback (string).\\n\\n\"\n",
    "        f\"--- Original Text ---\\n{text_chunk}\\n\\n\"\n",
    "        f\"--- Notes ---\\n{notes}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = await gemini_client.chat.completions.create(\n",
    "            model=\"gemini-flash2.5\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        return Evaluation(**data)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Gemini evaluation error: {e}\")\n",
    "        return Evaluation(is_acceptable=True, feedback=f\"Evaluation failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "767f08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 2500):\n",
    "    \"\"\"Splits long text into smaller chunks for better processing.\"\"\"\n",
    "    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e6b7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_file(notes_markdown: str, source_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert Markdown notes into a simple academic PDF.\n",
    "    Automatically names it after the source textbook.\n",
    "    \"\"\"\n",
    "    title = os.path.splitext(os.path.basename(source_filename))[0].replace('_', ' ').title()\n",
    "    output_filename = f\"{os.path.splitext(source_filename)[0]}_notes.pdf\"\n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "    # Title\n",
    "    pdf.set_font(\"Arial\", \"B\", 18)\n",
    "    pdf.cell(0, 10, f\"Notes for {title}\", 0, 1, \"C\")\n",
    "    pdf.ln(10)\n",
    "\n",
    "    # Body text\n",
    "    pdf.set_font(\"Arial\", \"\", 11)\n",
    "\n",
    "    try:\n",
    "        pdf.write_markdown(notes_markdown)\n",
    "        pdf.output(output_filename)\n",
    "        print(f\"‚úÖ PDF created: {output_filename}\")\n",
    "        return output_filename\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è PDF creation error: {e}\")\n",
    "        fallback = f\"{os.path.splitext(source_filename)[0]}_notes.md\"\n",
    "        with open(fallback, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Notes for {title}\\n\\n{notes_markdown}\")\n",
    "        print(f\"Saved fallback Markdown: {fallback}\")\n",
    "        return fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f509c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_textbook(file, progress=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Extracts text, summarizes it, evaluates quality, and outputs PDF + download link.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return \"Please upload a textbook to begin.\", None\n",
    "\n",
    "    pdf_file_path = file.name\n",
    "    reader = PdfReader(pdf_file_path)\n",
    "    num_pages = len(reader.pages)\n",
    "\n",
    "    # Step 1 ‚Äî Extract\n",
    "    progress(0, desc=\"Step 1/4: Extracting text...\")\n",
    "    full_text = \"\"\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        progress((i + 1) / num_pages, desc=f\"Extracting Page {i + 1}/{num_pages}\")\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            full_text += page_text + \"\\n\"\n",
    "\n",
    "    if not full_text.strip():\n",
    "        return \"‚ö†Ô∏è No text extracted from the PDF.\", None\n",
    "\n",
    "    print(f\"‚úÖ Extracted {len(full_text)} characters from {num_pages} pages.\")\n",
    "\n",
    "    # Step 2 ‚Äî Chunk\n",
    "    chunks = chunk_text(full_text)\n",
    "    num_chunks = len(chunks)\n",
    "    all_notes = []\n",
    "\n",
    "    progress(0, desc=\"Step 2/4: Generating notes...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        progress((i + 1) / num_chunks, desc=f\"Generating Chunk {i + 1}/{num_chunks}\")\n",
    "        notes_chunk = await generate_notes(chunk)\n",
    "        all_notes.append(notes_chunk)\n",
    "\n",
    "    combined_notes = \"\\n\\n---\\n\\n\".join(all_notes)\n",
    "\n",
    "    # Step 3 ‚Äî PDF\n",
    "    progress(1, desc=\"Step 3/4: Creating PDF...\")\n",
    "    pdf_output_path = create_pdf_file(combined_notes, pdf_file_path)\n",
    "\n",
    "    # Step 4 ‚Äî Return both preview + file\n",
    "    if os.path.exists(pdf_output_path):\n",
    "        message = f\"‚úÖ Notes generated successfully!\\n\\n**Saved as:** {os.path.basename(pdf_output_path)}\"\n",
    "        return message, pdf_output_path\n",
    "    else:\n",
    "        return \"‚ùå PDF generation failed.\", None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "399ef01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_notes_interface(file, progress=gr.Progress(track_tqdm=True)):\n",
    "    \"\"\"Handles Gradio flow.\"\"\"\n",
    "    if file is not None:\n",
    "        return await process_textbook(file, progress)\n",
    "    return \"Please upload a textbook.\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\gradio\\interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\gradio\\routes.py\", line 1671, in get_upload_progress\n",
      "    await asyncio.wait_for(\n",
      "        file_upload_statuses.is_tracked(upload_id), timeout=3\n",
      "    )\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\tasks.py\", line 507, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\Session-04&05\\textbook-notebook-Agent\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 528, in is_tracked\n",
      "    return await self._signals[upload_id].wait()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x000001D76E0C8B30 [unset]> is bound to a different event loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 50951 characters from 37 pages.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-flash2.5 is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "‚úÖ Evaluation passed.\n",
      "‚ö†Ô∏è PDF creation error: 'FPDF' object has no attribute 'write_markdown'\n",
      "Saved fallback Markdown: C:\\Users\\kolla\\AppData\\Local\\Temp\\gradio\\2627a5cfa3bc1a27d8e89dd6869558e5f2c8a0b37b92dcb0a3ba5e78b7190bcd\\the-4-hour-workweek-expanded-and-updated-by-timothy-ferriss_notes.md\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=create_notes_interface,\n",
    "    inputs=gr.File(label=\"üìò Upload Textbook (PDF)\"),\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"üßæ Status / Summary\"),\n",
    "        gr.File(label=\"üì• Download Generated Notes (.pdf)\")\n",
    "    ],\n",
    "    title=\"AI Textbook ‚Üí Notebook Notes Generator\",\n",
    "    description=(\n",
    "        \"Upload any textbook (PDF). The local LLaMA 3 (8B) model summarizes it into concise academic notes. \"\n",
    "        \"Gemini evaluates quality, and the output is auto-saved as a clean PDF titled after the textbook.\"\n",
    "    ),\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_name=\"127.0.0.1\", share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c39332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
