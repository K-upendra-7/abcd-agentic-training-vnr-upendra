{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad76f3ba",
   "metadata": {},
   "source": [
    "# AI Agent: Textbook to Notebook Notes Generator \n",
    "Using LLaMA 3:8B for generation and GPT-4o-mini for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96ca83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "import textwrap\n",
    "import asyncio\n",
    "from PyPDF2 import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "from fpdf import FPDF\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46c97c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6347600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key not found. Please set it in your .env file.\n",
      "You can get a free API key from: https://platform.openai.com/api-keys\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key found, starting with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please set it in your .env file.\")\n",
    "    print(\"You can get a free API key from: https://platform.openai.com/api-keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e99713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients for both LLaMA (local) and OpenAI (evaluation)\n",
    "llama_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"  # dummy key for Ollama\n",
    ")\n",
    "\n",
    "openai_client = AsyncOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4491724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    \"\"\"Defines evaluator output.\"\"\"\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443ccee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_notes_with_llama(text_chunk: str, chapter_info: str = \"\", retries=2, feedback=\"\"):\n",
    "    \"\"\"\n",
    "    Generate structured notes in PDF-friendly format using LLaMA 3:8B.\n",
    "    Auto-retries with feedback from GPT-4o-mini evaluation if needed.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are an expert academic assistant specialized in creating comprehensive textbook notes. \"\n",
    "        \"Your task is to produce clear, well-structured notes that are perfect for PDF output.\\n\\n\"\n",
    "        \"GUIDELINES:\\n\"\n",
    "        \"1. Use clear hierarchical headings (Chapter Title, Main Sections, Subsections)\\n\"\n",
    "        \"2. Include bullet points for key concepts and definitions\\n\"\n",
    "        \"3. Provide concise summaries of main ideas\\n\"\n",
    "        \"4. Highlight important formulas, theorems, or principles\\n\"\n",
    "        \"5. Include practical examples or applications when available\\n\"\n",
    "        \"6. Structure content for easy reading and studying\\n\"\n",
    "        \"7. Use clean formatting without special symbols like *, #, +, - except for bullet points\\n\"\n",
    "        \"8. Focus on extracting the most valuable academic content that students would need for exams and understanding.\\n\\n\"\n",
    "        \"IMPORTANT: Avoid using special symbols *, #, +, - in the content except for proper bullet points.\"\n",
    "    )\n",
    "\n",
    "    if chapter_info:\n",
    "        user_prompt = (\n",
    "            f\"Generate comprehensive academic notes for CHAPTER: {chapter_info}\\n\\n\"\n",
    "            f\"TEXTBOOK CONTENT:\\n{text_chunk}\\n\\n\"\n",
    "            \"Please create well-structured notes with the following sections:\\n\"\n",
    "            \"1. Chapter Overview & Key Objectives\\n\"\n",
    "            \"2. Main Concepts & Definitions\\n\"\n",
    "            \"3. Important Formulas/Theorems/Principles\\n\"\n",
    "            \"4. Key Examples & Applications\\n\"\n",
    "            \"5. Chapter Summary & Key Takeaways\\n\"\n",
    "            \"6. Study Questions (if applicable)\\n\\n\"\n",
    "            \"Format using clear headings and organized sections. Avoid special symbols.\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = f\"Generate comprehensive academic notes for the following textbook content:\\n{text_chunk}\"\n",
    "\n",
    "    if feedback:\n",
    "        user_prompt = f\"IMPROVEMENT FEEDBACK FROM PREVIOUS ATTEMPT:\\n{feedback}\\n\\nPlease revise your notes accordingly:\\n{user_prompt}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(f\"üìù Generating notes with LLaMA for: {chapter_info[:50]}...\")\n",
    "        response = await llama_client.chat.completions.create(\n",
    "            model=\"llama3:8b\",\n",
    "            messages=messages,\n",
    "            temperature=0.3,\n",
    "            max_tokens=2000,\n",
    "        )\n",
    "        notes = response.choices[0].message.content\n",
    "        print(f\"‚úÖ LLaMA generation completed for: {chapter_info[:50]}...\")\n",
    "        \n",
    "        # Apply guard rails to clean the notes\n",
    "        notes = apply_guard_rails(notes)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLaMA generation error: {e}\")\n",
    "        return f\"Error generating notes with LLaMA: {e}\"\n",
    "\n",
    "    # Evaluate quality and retry if needed\n",
    "    if retries > 0:\n",
    "        evaluation = await evaluate_notes_with_gpt4omini(text_chunk, notes, chapter_info)\n",
    "        if not evaluation.is_acceptable:\n",
    "            print(f\"üîÅ Retrying generation with feedback: {evaluation.feedback[:100]}...\")\n",
    "            return await generate_notes_with_llama(text_chunk, chapter_info, retries - 1, evaluation.feedback)\n",
    "        else:\n",
    "            print(f\"‚úÖ Evaluation passed for: {chapter_info[:50]}...\")\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e656ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_guard_rails(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply guard rails to clean unwanted symbols and ensure proper formatting.\n",
    "    \"\"\"\n",
    "    # Remove unwanted symbols but preserve structure\n",
    "    cleaned_text = text\n",
    "    \n",
    "    # Replace multiple special symbols with clean alternatives\n",
    "    replacements = {\n",
    "        # Remove or replace problematic symbols\n",
    "        '***': '---',\n",
    "        '**': '',  # Remove asterisks used for emphasis\n",
    "        '*': '‚Ä¢',  # Convert single asterisks to proper bullets\n",
    "        '##': '==',\n",
    "        '#': '',   # Remove hash symbols\n",
    "        '++': '',  # Remove plus symbols\n",
    "        '--': '‚Äî', # Convert to proper em dash\n",
    "    }\n",
    "    \n",
    "    for symbol, replacement in replacements.items():\n",
    "        cleaned_text = cleaned_text.replace(symbol, replacement)\n",
    "    \n",
    "    # Remove any remaining isolated special symbols\n",
    "    cleaned_text = re.sub(r'(?<!\\w)[*#+](?!\\w)', '', cleaned_text)\n",
    "    \n",
    "    # Ensure proper line breaks and spacing\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[ \\t]+', ' ', cleaned_text)\n",
    "    \n",
    "    # Clean up bullet points\n",
    "    cleaned_text = re.sub(r'^[\\s]*[-*‚Ä¢][\\s]+', '‚Ä¢ ', cleaned_text, flags=re.MULTILINE)\n",
    "    \n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ef4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_notes_with_gpt4omini(original_text: str, generated_notes: str, chapter_info: str = \"\") -> Evaluation:\n",
    "    \"\"\"\n",
    "    Evaluates generated notes using GPT-4o-mini for accuracy, completeness, and academic quality.\n",
    "    \"\"\"\n",
    "    evaluation_prompt = (\n",
    "        \"You are a strict academic quality evaluator for textbook notes. \"\n",
    "        \"Evaluate the generated notes based on these CRITICAL criteria:\\n\\n\"\n",
    "        \"ESSENTIAL CRITERIA:\\n\"\n",
    "        \"1. ACCURACY: Do the notes correctly represent the original content without factual errors?\\n\"\n",
    "        \"2. COMPLETENESS: Are all key concepts, definitions, and important information included?\\n\"\n",
    "        \"3. STRUCTURE: Is the content well-organized with clear headings and logical flow?\\n\"\n",
    "        \"4. CLARITY: Is the information presented clearly and concisely for student understanding?\\n\"\n",
    "        \"5. ACADEMIC VALUE: Would these notes be genuinely useful for studying and exam preparation?\\n\"\n",
    "        \"6. CLEAN FORMATTING: Are the notes free of unwanted symbols like *, #, +, - except for proper formatting?\\n\\n\"\n",
    "        \"EVALUATION RULES:\\n\"\n",
    "        \"- REJECT if any key concepts are missing or misrepresented\\n\"\n",
    "        \"- REJECT if the structure is confusing or poorly organized\\n\"\n",
    "        \"- REJECT if the notes lack academic depth or practical study value\\n\"\n",
    "        \"- REJECT if there are excessive special symbols that affect readability\\n\"\n",
    "        \"- ACCEPT only if all criteria are satisfactorily met\\n\\n\"\n",
    "        f\"CHAPTER CONTEXT: {chapter_info}\\n\\n\"\n",
    "        f\"ORIGINAL TEXT (excerpt):\\n{original_text[:1500]}...\\n\\n\"\n",
    "        f\"GENERATED NOTES:\\n{generated_notes}\\n\\n\"\n",
    "        \"Provide your evaluation in JSON format with these exact keys:\\n\"\n",
    "        \"- 'is_acceptable' (boolean): true only if all criteria are met\\n\"\n",
    "        \"- 'feedback' (string): Specific, actionable feedback for improvement if rejected, or confirmation of quality if accepted\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        print(f\"üß™ Evaluating notes with GPT-4o-mini for: {chapter_info[:50]}...\")\n",
    "        response = await openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            max_tokens=800,\n",
    "            temperature=0.1,\n",
    "        )\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        evaluation = Evaluation(**data)\n",
    "        print(f\"‚úÖ Evaluation completed: {'ACCEPTED' if evaluation.is_acceptable else 'REJECTED'} - {chapter_info[:50]}...\")\n",
    "        return evaluation\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è GPT-4o-mini evaluation error: {e}\")\n",
    "        return Evaluation(is_acceptable=True, feedback=f\"Evaluation failed, defaulting to accept: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118536cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_chapters(text: str):\n",
    "    \"\"\"\n",
    "    Detect chapters in the text using comprehensive patterns.\n",
    "    Returns list of chapter dictionaries with metadata.\n",
    "    \"\"\"\n",
    "    # Comprehensive chapter patterns\n",
    "    chapter_patterns = [\n",
    "        r'^CHAPTER\\s+(\\d+[A-Z]*(?:\\.\\d+)*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "        r'^Chapter\\s+(\\d+[A-Z]*(?:\\.\\d+)*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "        r'^(\\d+[A-Z]*(?:\\.\\d+)*)\\s+([^\\n]{10,})',\n",
    "        r'^(\\d+\\.\\d*)\\s+([^\\n]{10,})',\n",
    "        r'^([IVXLCDM]+)\\s+([^\\n]{10,})',\n",
    "        r'^Part\\s+(\\d+[A-Z]*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "        r'^PART\\s+(\\d+[A-Z]*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "        r'^Section\\s+(\\d+[A-Z]*(?:\\.\\d+)*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "        r'^SECTION\\s+(\\d+[A-Z]*(?:\\.\\d+)*)[\\s:\\-]+\\s*([^\\n]{5,})',\n",
    "    ]\n",
    "    \n",
    "    chapters = []\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if len(line) < 8:  # Too short to be a meaningful chapter title\n",
    "            continue\n",
    "            \n",
    "        # Check if line is in uppercase or has chapter-like formatting\n",
    "        is_likely_chapter = (line.isupper() or \n",
    "                           re.search(r'\\b(chapter|part|section)\\b', line, re.IGNORECASE) or\n",
    "                           re.match(r'^(?:\\d+|[IVXLCDM]+)(?:\\.\\s|\\s+[A-Z])', line))\n",
    "        \n",
    "        for pattern in chapter_patterns:\n",
    "            matches = re.findall(pattern, line, re.IGNORECASE | re.MULTILINE)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    if len(match) == 2:\n",
    "                        chapter_num = match[0].strip()\n",
    "                        chapter_title = match[1].strip()\n",
    "                        # Additional validation for meaningful titles\n",
    "                        if (len(chapter_title) > 5 and \n",
    "                            not chapter_title.lower().startswith(('page', 'copyright', 'published')) and\n",
    "                            not re.search(r'^\\d+$', chapter_title)):\n",
    "                            \n",
    "                            start_idx = text.find(line)\n",
    "                            chapters.append({\n",
    "                                'number': chapter_num,\n",
    "                                'title': chapter_title,\n",
    "                                'start_idx': start_idx,\n",
    "                                'line_index': i,\n",
    "                                'full_line': line\n",
    "                            })\n",
    "                            break\n",
    "    \n",
    "    # Remove duplicates based on position\n",
    "    chapters = sorted(chapters, key=lambda x: x['start_idx'])\n",
    "    unique_chapters = []\n",
    "    seen_positions = set()\n",
    "    \n",
    "    for chapter in chapters:\n",
    "        if chapter['start_idx'] not in seen_positions:\n",
    "            unique_chapters.append(chapter)\n",
    "            seen_positions.add(chapter['start_idx'])\n",
    "    \n",
    "    # If no chapters detected, create content-based chunks\n",
    "    if not unique_chapters:\n",
    "        print(\"No chapter patterns detected, creating content-based chunks...\")\n",
    "        return create_content_chunks(text)\n",
    "    \n",
    "    # Calculate end indices\n",
    "    for i in range(len(unique_chapters) - 1):\n",
    "        unique_chapters[i]['end_idx'] = unique_chapters[i + 1]['start_idx']\n",
    "    if unique_chapters:\n",
    "        unique_chapters[-1]['end_idx'] = len(text)\n",
    "    \n",
    "    print(f\"üìö Detected {len(unique_chapters)} chapters:\")\n",
    "    for chap in unique_chapters[:5]:\n",
    "        print(f\"  - {chap['number']}: {chap['title']}\")\n",
    "    if len(unique_chapters) > 5:\n",
    "        print(f\"  ... and {len(unique_chapters) - 5} more chapters\")\n",
    "    \n",
    "    return unique_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb477c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_content_chunks(text: str, max_chunk_size: int = 4000):\n",
    "    \"\"\"\n",
    "    Create content-based chunks when chapter detection fails.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "            \n",
    "        sentence_size = len(sentence)\n",
    "        if current_size + sentence_size > max_chunk_size and current_chunk:\n",
    "            # Save current chunk and start new one\n",
    "            chunk_text = ' '.join(current_chunk)\n",
    "            chunks.append({\n",
    "                'number': f\"Section {len(chunks) + 1}\",\n",
    "                'title': f\"Content Part {len(chunks) + 1}\",\n",
    "                'start_idx': text.find(chunk_text),\n",
    "                'end_idx': text.find(chunk_text) + len(chunk_text),\n",
    "                'line_index': len(chunks)\n",
    "            })\n",
    "            current_chunk = [sentence]\n",
    "            current_size = sentence_size\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_size += sentence_size\n",
    "    \n",
    "    # Add the last chunk\n",
    "    if current_chunk:\n",
    "        chunk_text = ' '.join(current_chunk)\n",
    "        chunks.append({\n",
    "            'number': f\"Section {len(chunks) + 1}\",\n",
    "            'title': f\"Content Part {len(chunks) + 1}\",\n",
    "            'start_idx': text.find(chunk_text),\n",
    "            'end_idx': text.find(chunk_text) + len(chunk_text),\n",
    "            'line_index': len(chunks)\n",
    "        })\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db03571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chapter_content(text: str, chapter_info: dict):\n",
    "    \"\"\"\n",
    "    Extract content for a specific chapter with cleaning.\n",
    "    \"\"\"\n",
    "    start = chapter_info['start_idx']\n",
    "    end = chapter_info['end_idx']\n",
    "    \n",
    "    chapter_text = text[start:end].strip()\n",
    "    \n",
    "    # Clean up the text\n",
    "    chapter_text = re.sub(r'\\n\\s*\\n', '\\n\\n', chapter_text)  # Remove excessive newlines\n",
    "    chapter_text = re.sub(r'[ \\t]+', ' ', chapter_text)  # Normalize spaces\n",
    "    \n",
    "    return chapter_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa58ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text_for_pdf(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove or replace problematic characters that cause font issues.\n",
    "    Uses simple ASCII replacements for maximum compatibility.\n",
    "    \"\"\"\n",
    "    # First apply guard rails\n",
    "    text = apply_guard_rails(text)\n",
    "    \n",
    "    # Then additional PDF-specific sanitization\n",
    "    replacements = {\n",
    "        '‚Ä¢': '-',      '‚Äì': '-',      '‚Äî': '-',      '‚Äú': '\"',      '‚Äù': '\"',\n",
    "        '‚Äò': \"'\",      '‚Äô': \"'\",      '‚Ä¶': '...',    '‚Üí': '->',     '‚Üê': '<-',\n",
    "        '‚â•': '>=',     '‚â§': '<=',     '√ó': 'x',      '√∑': '/',      '¬±': '+/-',\n",
    "        'Œ±': 'alpha',  'Œ≤': 'beta',   'Œ≥': 'gamma',  'Œ¥': 'delta',  'Œµ': 'epsilon',\n",
    "        'Œº': 'mu',     'œÉ': 'sigma',  'œÄ': 'pi',     'Œ∏': 'theta',  'Œª': 'lambda',\n",
    "        '¬∞': 'deg',    '‚àû': 'inf',    '‚â†': '!=',     '‚â°': '===',    '‚àö': 'sqrt',\n",
    "        '‚àë': 'sum',    '‚àè': 'prod',   '‚à´': 'integral', '‚àÇ': 'partial',\n",
    "    }\n",
    "    \n",
    "    for unicode_char, ascii_char in replacements.items():\n",
    "        text = text.replace(unicode_char, ascii_char)\n",
    "    \n",
    "    # Remove any remaining non-ASCII characters\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Final cleanup of unwanted symbols\n",
    "    text = re.sub(r'(?<!\\w)[*#+](?!\\w)', '', text)  # Remove isolated special symbols\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c9ba24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_file(notes_by_chapter: dict, source_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert chapter-wise notes into a well-formatted academic PDF with robust font handling.\n",
    "    \"\"\"\n",
    "    title = os.path.splitext(os.path.basename(source_filename))[0].replace('_', ' ').title()\n",
    "    output_filename = f\"{os.path.splitext(source_filename)[0]}_chapter_notes.pdf\"\n",
    "\n",
    "    # Create PDF with core fonts only for maximum compatibility\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    \n",
    "    # Use only core fonts that are guaranteed to work\n",
    "    font_family = \"Helvetica\"  # Core PDF font that always works\n",
    "    \n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Title\n",
    "    pdf.set_font(font_family, \"B\", 16)\n",
    "    pdf.cell(0, 10, sanitize_text_for_pdf(f\"Chapter-wise Academic Notes: {title}\"), 0, 1, \"C\")\n",
    "    pdf.ln(5)\n",
    "    \n",
    "    # Metadata\n",
    "    pdf.set_font(font_family, \"I\", 10)\n",
    "    pdf.cell(0, 8, sanitize_text_for_pdf(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\"), 0, 1, \"C\")\n",
    "    pdf.cell(0, 8, sanitize_text_for_pdf(f\"Total Chapters: {len(notes_by_chapter)}\"), 0, 1, \"C\")\n",
    "    pdf.cell(0, 8, sanitize_text_for_pdf(f\"AI Models: LLaMA 3:8B (Generation) + GPT-4o-mini (Evaluation)\"), 0, 1, \"C\")\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    # Table of Contents\n",
    "    pdf.set_font(font_family, \"B\", 14)\n",
    "    pdf.cell(0, 10, sanitize_text_for_pdf(\"Table of Contents\"), 0, 1, \"C\")\n",
    "    pdf.ln(8)\n",
    "    \n",
    "    pdf.set_font(font_family, \"\", 11)\n",
    "    for chapter_num, notes in notes_by_chapter.items():\n",
    "        # Extract chapter title from notes\n",
    "        lines = notes.split('\\n')\n",
    "        chapter_title = \"Chapter Content\"\n",
    "        for line in lines:\n",
    "            if line.strip() and not line.startswith(('#', '-', '*')):\n",
    "                chapter_title = line.strip()[:50] + \"...\" if len(line.strip()) > 50 else line.strip()\n",
    "                break\n",
    "        \n",
    "        toc_line = sanitize_text_for_pdf(f\"Chapter {chapter_num}: {chapter_title}\")\n",
    "        pdf.cell(0, 7, toc_line, 0, 1)\n",
    "    pdf.ln(15)\n",
    "    \n",
    "    # Chapter contents\n",
    "    for chapter_num, notes in notes_by_chapter.items():\n",
    "        # Add new page for each chapter\n",
    "        pdf.add_page()\n",
    "        \n",
    "        # Chapter header\n",
    "        pdf.set_font(font_family, \"B\", 16)\n",
    "        pdf.cell(0, 10, sanitize_text_for_pdf(f\"Chapter {chapter_num}\"), 0, 1, \"C\")\n",
    "        pdf.ln(8)\n",
    "        \n",
    "        # Process notes content\n",
    "        pdf.set_font(font_family, \"\", 11)\n",
    "        lines = notes.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                pdf.ln(3)\n",
    "                continue\n",
    "                \n",
    "            # Use sanitized text for maximum compatibility\n",
    "            safe_line = sanitize_text_for_pdf(line)\n",
    "            \n",
    "            # Skip lines that are just special symbols\n",
    "            if re.match(r'^[*#+-]+$', safe_line.strip()):\n",
    "                continue\n",
    "                \n",
    "            # Handle markdown elements with improved formatting\n",
    "            if safe_line.startswith('# '):\n",
    "                pdf.set_font(font_family, \"B\", 14)\n",
    "                pdf.cell(0, 8, safe_line[2:], 0, 1)\n",
    "                pdf.set_font(font_family, \"\", 11)\n",
    "                pdf.ln(2)\n",
    "            elif safe_line.startswith('## '):\n",
    "                pdf.set_font(font_family, \"B\", 12)\n",
    "                pdf.cell(0, 7, safe_line[3:], 0, 1)\n",
    "                pdf.set_font(font_family, \"\", 11)\n",
    "                pdf.ln(2)\n",
    "            elif safe_line.startswith('### '):\n",
    "                pdf.set_font(font_family, \"B\", 11)\n",
    "                pdf.cell(0, 6, safe_line[4:], 0, 1)\n",
    "                pdf.set_font(font_family, \"\", 11)\n",
    "                pdf.ln(1)\n",
    "            elif safe_line.startswith('- ') or safe_line.startswith('‚Ä¢ '):\n",
    "                pdf.set_font(font_family, \"\", 11)\n",
    "                pdf.cell(8)  # Indent\n",
    "                bullet_text = safe_line[2:]\n",
    "                # Use simple hyphen for bullets to avoid Unicode issues\n",
    "                if len(bullet_text) > 80:\n",
    "                    pdf.multi_cell(0, 5, f\"- {bullet_text}\")\n",
    "                else:\n",
    "                    pdf.cell(0, 5, f\"- {bullet_text}\", 0, 1)\n",
    "            elif re.match(r'^\\d+\\.\\s', safe_line):\n",
    "                pdf.set_font(font_family, \"\", 11)\n",
    "                pdf.cell(8)  # Indent\n",
    "                numbered_text = safe_line\n",
    "                if len(numbered_text) > 80:\n",
    "                    pdf.multi_cell(0, 5, numbered_text)\n",
    "                else:\n",
    "                    pdf.cell(0, 5, numbered_text, 0, 1)\n",
    "            elif safe_line == '---' or safe_line == '***':\n",
    "                pdf.ln(3)\n",
    "                pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "                pdf.ln(3)\n",
    "            else:\n",
    "                # Regular paragraph with multi_cell for wrapping\n",
    "                pdf.multi_cell(0, 5, safe_line)\n",
    "            \n",
    "            pdf.ln(2)\n",
    "        \n",
    "        pdf.ln(10)\n",
    "        \n",
    "        # Add chapter separator\n",
    "        pdf.set_draw_color(200, 200, 200)\n",
    "        pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "        pdf.ln(5)\n",
    "    \n",
    "    # Footer\n",
    "    pdf.set_y(-15)\n",
    "    pdf.set_font(font_family, \"I\", 8)\n",
    "    pdf.cell(0, 10, sanitize_text_for_pdf(f\"Generated from: {os.path.basename(source_filename)} ‚Ä¢ Page {pdf.page_no()}\"), 0, 0, 'C')\n",
    "    \n",
    "    try:\n",
    "        pdf.output(output_filename)\n",
    "        print(f\"‚úÖ PDF created successfully: {output_filename}\")\n",
    "        return output_filename\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è PDF creation error: {e}\")\n",
    "        # Create comprehensive fallback text file\n",
    "        fallback = f\"{os.path.splitext(source_filename)[0]}_detailed_notes.txt\"\n",
    "        with open(fallback, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"CHAPTER-WISE ACADEMIC NOTES\\n\")\n",
    "            f.write(f\"Textbook: {title}\\n\")\n",
    "            f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "            f.write(f\"AI Models: LLaMA 3:8B (Generation) + GPT-4o-mini (Evaluation)\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            for chapter_num, notes in notes_by_chapter.items():\n",
    "                f.write(f\"CHAPTER {chapter_num}\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\")\n",
    "                f.write(notes)\n",
    "                f.write(\"\\n\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"üìù Saved detailed fallback text file: {fallback}\")\n",
    "        return fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4da8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def process_textbook(file, progress=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Main processing pipeline: Extract text, detect chapters, generate notes with LLaMA, \n",
    "    evaluate with GPT-4o-mini, and output PDF.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return \"Please upload a textbook PDF to begin.\", None\n",
    "\n",
    "    try:\n",
    "        pdf_file_path = file.name\n",
    "        reader = PdfReader(pdf_file_path)\n",
    "        num_pages = len(reader.pages)\n",
    "\n",
    "        # Step 1 ‚Äî Extract text from PDF\n",
    "        progress(0, desc=\"Step 1/5: Extracting text from PDF...\")\n",
    "        full_text = \"\"\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            progress((i + 1) / num_pages / 3, desc=f\"Extracting Page {i + 1}/{num_pages}\")\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                full_text += page_text + \"\\n\"\n",
    "\n",
    "        if not full_text.strip():\n",
    "            return \"‚ö†Ô∏è No text could be extracted from the PDF. The file might be scanned or image-based.\", None\n",
    "\n",
    "        print(f\"‚úÖ Extracted {len(full_text)} characters from {num_pages} pages.\")\n",
    "\n",
    "        # Step 2 ‚Äî Detect chapters\n",
    "        progress(0.33, desc=\"Step 2/5: Analyzing textbook structure...\")\n",
    "        chapters = detect_chapters(full_text)\n",
    "        \n",
    "        if not chapters:\n",
    "            return \"‚ö†Ô∏è No clear chapter structure detected. Try a different textbook or check if the PDF has selectable text.\", None\n",
    "\n",
    "        # Step 3 ‚Äî Generate notes for each chapter using LLaMA\n",
    "        notes_by_chapter = {}\n",
    "        total_chapters = len(chapters)\n",
    "        \n",
    "        progress(0.4, desc=\"Step 3/5: Generating notes with LLaMA 3:8B...\")\n",
    "        for i, chapter in enumerate(chapters):\n",
    "            progress_percent = 0.4 + (i / total_chapters) * 0.4\n",
    "            progress(progress_percent, desc=f\"Processing Chapter {i + 1}/{total_chapters} with LLaMA\")\n",
    "            \n",
    "            chapter_content = extract_chapter_content(full_text, chapter)\n",
    "            chapter_info = f\"{chapter['number']}: {chapter['title']}\"\n",
    "            \n",
    "            if len(chapter_content) > 200:  # Only process if there's substantial content\n",
    "                try:\n",
    "                    notes = await generate_notes_with_llama(chapter_content, chapter_info)\n",
    "                    notes_by_chapter[chapter['number']] = notes\n",
    "                    print(f\"‚úÖ Completed chapter {chapter['number']}\")\n",
    "                except Exception as e:\n",
    "                    notes_by_chapter[chapter['number']] = f\"Chapter {chapter_info}\\n\\nError generating notes: {str(e)}\"\n",
    "                    print(f\"‚ùå Error in chapter {chapter['number']}: {e}\")\n",
    "            else:\n",
    "                notes_by_chapter[chapter['number']] = f\"Chapter {chapter_info}\\n\\nInsufficient content for detailed notes (only {len(chapter_content)} characters).\"\n",
    "                print(f\"‚ö†Ô∏è Skipped chapter {chapter['number']} (insufficient content)\")\n",
    "\n",
    "        # Step 4 ‚Äî Create PDF\n",
    "        progress(0.85, desc=\"Step 4/5: Creating formatted PDF...\")\n",
    "        pdf_output_path = create_pdf_file(notes_by_chapter, pdf_file_path)\n",
    "\n",
    "        # Step 5 ‚Äî Return results\n",
    "        progress(1.0, desc=\"Step 5/5: Finalizing...\")\n",
    "        if os.path.exists(pdf_output_path):\n",
    "            message = (\n",
    "                f\"‚úÖ **Chapter-wise notes generated successfully!**\\n\\n\"\n",
    "                f\"**Textbook Analysis Summary:**\\n\"\n",
    "                f\"‚Ä¢ Pages processed: {num_pages}\\n\"\n",
    "                f\"‚Ä¢ Chapters detected: {len(chapters)}\\n\"\n",
    "                f\"‚Ä¢ Notes generated: {len(notes_by_chapter)}\\n\"\n",
    "                f\"‚Ä¢ Output file: `{os.path.basename(pdf_output_path)}`\\n\\n\"\n",
    "                f\"**AI Pipeline Used:**\\n\"\n",
    "                f\"‚Ä¢ LLaMA 3:8B for content generation\\n\"\n",
    "                f\"‚Ä¢ GPT-4o-mini for quality evaluation\\n\\n\"\n",
    "                f\"**Processed Chapters:**\\n\" +\n",
    "                \"\\n\".join([f\"  ‚Ä¢ Chapter {num}\" for num in notes_by_chapter.keys()][:8])\n",
    "            )\n",
    "            if len(notes_by_chapter) > 8:\n",
    "                message += f\"\\n  ‚Ä¢ ... and {len(notes_by_chapter) - 8} more chapters\"\n",
    "            \n",
    "            message += f\"\\n\\n**Download your chapter-wise notes using the file button below!**\"\n",
    "            return message, pdf_output_path\n",
    "        else:\n",
    "            return \"‚ùå PDF generation failed. Check the console for errors.\", None\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error processing PDF: {str(e)}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2870406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_notes_interface(file, progress=gr.Progress(track_tqdm=True)):\n",
    "    \"\"\"Handles Gradio interface flow synchronously to avoid event loop issues.\"\"\"\n",
    "    if file is not None:\n",
    "        # Run the async function in the current event loop\n",
    "        try:\n",
    "            import asyncio\n",
    "            # Try to get the running event loop, create new if none\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "            except RuntimeError:\n",
    "                loop = asyncio.new_event_loop()\n",
    "                asyncio.set_event_loop(loop)\n",
    "            \n",
    "            # Run the async function\n",
    "            return loop.run_until_complete(process_textbook(file, progress))\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error: {str(e)}\", None\n",
    "    return \"Please upload a textbook PDF to generate chapter-wise notes.\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3614c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Ollama is running\n",
    "async def check_ollama_status():\n",
    "    \"\"\"Check if LLaMA 3:8B is available in Ollama.\"\"\"\n",
    "    try:\n",
    "        client = AsyncOpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "        models = await client.models.list()\n",
    "        llama_available = any('llama3:8b' in model.id for model in models.data)\n",
    "        if llama_available:\n",
    "            print(\"‚úÖ LLaMA 3:8B is available in Ollama\")\n",
    "        else:\n",
    "            print(\"‚ùå LLaMA 3:8B not found in Ollama. Please run: ollama pull llama3:8b\")\n",
    "        return llama_available\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cannot connect to Ollama: {e}\")\n",
    "        print(\"Please make sure Ollama is running: ollama serve\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb7d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ All systems ready! Starting web interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 19920 characters from 11 pages.\n",
      "üìö Detected 16 chapters:\n",
      "  - I: S I SI S I SI S ell my Dreamsell my Dreamsell my Dreamsell my Dreamsell my Dreams\n",
      "  - I: could not have imagined a more suitable spot for my\n",
      "  - I: stayed in Vienna for more than a month, sharing the\n",
      "  - Civil: W ar, on a stopover during a long sea voyage to\n",
      "  - I: have never known anyone closer to the idea one has\n",
      "  ... and 11 more chapters\n",
      "üìù Generating notes with LLaMA for: I: S I SI S I SI S ell my Dreamsell my Dreamsell m...\n",
      "‚úÖ LLaMA generation completed for: I: S I SI S I SI S ell my Dreamsell my Dreamsell m...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: S I SI S I SI S ell my Dreamsell my Dreamsell m...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: S I SI S I SI S ell my Dreamsell my Dreamsell m...\n",
      "‚úÖ Completed chapter I\n",
      "üìù Generating notes with LLaMA for: I: could not have imagined a more suitable spot fo...\n",
      "‚úÖ LLaMA generation completed for: I: could not have imagined a more suitable spot fo...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: could not have imagined a more suitable spot fo...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: could not have imagined a more suitable spot fo...\n",
      "‚úÖ Completed chapter I\n",
      "üìù Generating notes with LLaMA for: I: stayed in Vienna for more than a month, sharing...\n",
      "‚úÖ LLaMA generation completed for: I: stayed in Vienna for more than a month, sharing...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: stayed in Vienna for more than a month, sharing...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: stayed in Vienna for more than a month, sharing...\n",
      "‚úÖ Completed chapter I\n",
      "üìù Generating notes with LLaMA for: Civil: W ar, on a stopover during a long sea voyag...\n",
      "‚úÖ LLaMA generation completed for: Civil: W ar, on a stopover during a long sea voyag...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: Civil: W ar, on a stopover during a long sea voyag...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: Civil: W ar, on a stopover during a long sea voyag...\n",
      "‚úÖ Completed chapter Civil\n",
      "üìù Generating notes with LLaMA for: I: have never known anyone closer to the idea one ...\n",
      "‚úÖ LLaMA generation completed for: I: have never known anyone closer to the idea one ...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: have never known anyone closer to the idea one ...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: have never known anyone closer to the idea one ...\n",
      "‚úÖ Completed chapter I\n",
      "üìù Generating notes with LLaMA for: I: glanced over his shoulder , and it was true. Th...\n",
      "‚úÖ LLaMA generation completed for: I: glanced over his shoulder , and it was true. Th...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: glanced over his shoulder , and it was true. Th...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: glanced over his shoulder , and it was true. Th...\n",
      "‚úÖ Completed chapter I\n",
      "üìù Generating notes with LLaMA for: I: never saw her again or even wondered about her...\n",
      "‚úÖ LLaMA generation completed for: I: never saw her again or even wondered about her...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: I: never saw her again or even wondered about her...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: I: never saw her again or even wondered about her...\n",
      "‚úÖ Completed chapter I\n",
      "‚ö†Ô∏è Skipped chapter 1. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 2. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 3. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 1. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 2. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 1. (insufficient content)\n",
      "‚ö†Ô∏è Skipped chapter 2. (insufficient content)\n",
      "üìù Generating notes with LLaMA for: 3.: Bring out the contradiction in the last exchan...\n",
      "‚úÖ LLaMA generation completed for: 3.: Bring out the contradiction in the last exchan...\n",
      "üß™ Evaluating notes with GPT-4o-mini for: 3.: Bring out the contradiction in the last exchan...\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: 3.: Bring out the contradiction in the last exchan...\n",
      "‚úÖ Completed chapter 3.\n",
      "üìù Generating notes with LLaMA for: 4.: Comment on the ironical element in the story....\n",
      "‚úÖ LLaMA generation completed for: 4.: Comment on the ironical element in the story....\n",
      "üß™ Evaluating notes with GPT-4o-mini for: 4.: Comment on the ironical element in the story....\n",
      "‚ö†Ô∏è GPT-4o-mini evaluation error: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "‚úÖ Evaluation passed for: 4.: Comment on the ironical element in the story....\n",
      "‚úÖ Completed chapter 4.\n",
      "‚úÖ PDF created successfully: C:\\Users\\kolla\\AppData\\Local\\Temp\\gradio\\9d1f585023bbee10a956ef450312e39e0d4bec0d7c7c4dfda6190eb8846fa20d\\Textbook_chapter_notes.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:20: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, sanitize_text_for_pdf(f\"Chapter-wise Academic Notes: {title}\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:25: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 8, sanitize_text_for_pdf(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:26: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 8, sanitize_text_for_pdf(f\"Total Chapters: {len(notes_by_chapter)}\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:27: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 8, sanitize_text_for_pdf(f\"AI Models: LLaMA 3:8B (Generation) + GPT-4o-mini (Evaluation)\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:32: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, sanitize_text_for_pdf(\"Table of Contents\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:46: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 7, toc_line, 0, 1)\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:56: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, sanitize_text_for_pdf(f\"Chapter {chapter_num}\"), 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:108: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 5, numbered_text, 0, 1)\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:100: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 5, f\"- {bullet_text}\", 0, 1)\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_20880\\784599035.py:129: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  pdf.cell(0, 10, sanitize_text_for_pdf(f\"Generated from: {os.path.basename(source_filename)} ‚Ä¢ Page {pdf.page_no()}\"), 0, 0, 'C')\n"
     ]
    }
   ],
   "source": [
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=create_notes_interface,\n",
    "    inputs=gr.File(\n",
    "        label=\"Upload Textbook PDF\", \n",
    "        file_types=[\".pdf\"]\n",
    "    ),\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"Processing Report\"),\n",
    "        gr.File(label=\"Download Chapter-wise Notes\")\n",
    "    ],\n",
    "    title=\"AI Textbook to Chapter-wise Notes Generator\",\n",
    "    description=(\n",
    "        \"Transform textbooks into comprehensive chapter-wise notes using advanced AI!\\n\\n\"\n",
    "        \"LLaMA 3:8B generates detailed academic notes | \"\n",
    "        \"GPT-4o-mini ensures quality evaluation\\n\\n\"\n",
    "        \"What this AI pipeline does:\\n\"\n",
    "        \"1. Extracts text from your PDF textbook\\n\"\n",
    "        \"2. Automatically detects chapter structure\\n\"\n",
    "        \"3. Generates comprehensive notes using LLaMA 3:8B\\n\"\n",
    "        \"4. Evaluates quality with GPT-4o-mini\\n\"\n",
    "        \"5. Outputs a beautifully formatted PDF\\n\\n\"\n",
    "        \"Note: Upload textbooks with selectable text (not scanned images)\\n\\n\"\n",
    "        \"Perfect for: Students, Researchers, and Lifelong Learners!\"\n",
    "    ),\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"üéâ All systems ready! Starting web interface...\")\n",
    "iface.launch(\n",
    "    server_name=\"127.0.0.1\", \n",
    "    share=False,\n",
    "    show_error=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c83d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
