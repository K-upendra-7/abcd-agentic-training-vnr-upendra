{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704aaa23",
   "metadata": {},
   "source": [
    "\n",
    " # AI Agent: Textbook to Notebook Notes Generator \n",
    " \n",
    "This AI agent processes textbook PDFs, extracts content, generates summarized notes using LLaMA3,\n",
    " evaluates quality using GPT-4o-mini, and outputs clean PDF notes without markdown symbols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f45898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: accepts 1 arg(s), received 10\n",
      "Error: accepts 0 arg(s), received 9\n"
     ]
    }
   ],
   "source": [
    "# Install and set up Ollama with LLaMA3 model\n",
    "!ollama pull llama3:8b  # Download the LLaMA3 8B model for local use\n",
    "!ollama serve           # Start the Ollama server to serve the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5a2e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import os\n",
    "import json\n",
    "import gradio as gr      # For creating web interface\n",
    "import textwrap\n",
    "import asyncio\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Try importing PyMuPDF for PDF text extraction (alternative to PyPDF2)\n",
    "try:\n",
    "    import fitz  # PyMuPDF\n",
    "except Exception:\n",
    "    fitz = None\n",
    "\n",
    "from dotenv import load_dotenv  # For loading environment variables\n",
    "from openai import AsyncOpenAI   # For interacting with AI models\n",
    "from pydantic import BaseModel  # For data validation\n",
    "from fpdf import FPDF, XPos, YPos  # For PDF generation with modern positioning\n",
    "from datetime import datetime\n",
    "import re  # For regular expressions to clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de6e31fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "# This contains API keys for OpenAI and Google services\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecdfa0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key found, starting with: sk-proj-...\n",
      "Google API Key found, starting with: AIzaSyDn...\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and validate API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check if OpenAI API key is available\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key found, starting with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please set it in your .env file.\")\n",
    "\n",
    "# Check if Google API key is available\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key found, starting with: {google_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"Google API Key not found. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8decdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AI clients for different services\n",
    "\n",
    "# Ollama client for local LLaMA3 model\n",
    "ollama_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # Local Ollama server\n",
    "    api_key=\"ollama\"  # Dummy API key for Ollama\n",
    ")\n",
    "\n",
    "# GPT-4o-mini client for quality evaluation (using OpenAI API)\n",
    "gpt_eval_client = AsyncOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    # Using default OpenAI base URL for GPT-4o-mini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94d8424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data model for evaluation results using Pydantic\n",
    "# This ensures structured response from the quality evaluator\n",
    "class Evaluation(BaseModel):\n",
    "    \"\"\"Defines the structure for quality evaluation output.\"\"\"\n",
    "    is_acceptable: bool  # Whether the notes meet quality standards\n",
    "    feedback: str        # Detailed feedback for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4e9aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_notes(text_chunk: str, retries=2, feedback=\"\") -> str:\n",
    "    \"\"\"\n",
    "    Generate structured notes in clean text format without markdown symbols using LLaMA3.\n",
    "    \n",
    "    This function:\n",
    "    1. Sends text chunks to LLaMA3 model for summarization\n",
    "    2. Explicitly instructs the model to avoid markdown symbols\n",
    "    3. Cleans any remaining markdown from the output\n",
    "    4. Retries with feedback if quality evaluation fails\n",
    "    \n",
    "    Args:\n",
    "        text_chunk (str): The portion of textbook text to summarize\n",
    "        retries (int): Number of retry attempts if quality check fails\n",
    "        feedback (str): Feedback from previous evaluation to improve notes\n",
    "    \n",
    "    Returns:\n",
    "        str: Clean, formatted notes without markdown symbols\n",
    "    \"\"\"\n",
    "    # System prompt that explicitly forbids markdown and requests clean text\n",
    "    system_prompt = (\n",
    "        \"You are an expert academic assistant. \"\n",
    "        \"Produce clear, well-structured notes WITHOUT any markdown formatting. \"\n",
    "        \"DO NOT use #, *, -, **, or any other markdown symbols. \"\n",
    "        \"Use plain text with clear headings, bullet points using simple indentation, and concise summaries. \"\n",
    "        \"Focus on key ideas, definitions, and concepts from the provided text. \"\n",
    "        \"Format the content in a way that will look good when converted to PDF.\"\n",
    "    )\n",
    "\n",
    "    # Build user prompt with optional feedback for retries\n",
    "    if feedback:\n",
    "        user_prompt = (\n",
    "            f\"Improve the previous notes using this feedback:\\n{feedback}\\n\\n\"\n",
    "            f\"Original text:\\n{text_chunk}\\n\\n\"\n",
    "            f\"IMPORTANT: Do not use any markdown symbols like #, *, -, ** in your response.\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = (\n",
    "            f\"Generate concise academic notes in clean text format for the following text:\\n{text_chunk}\\n\\n\"\n",
    "            f\"IMPORTANT: Do not use any markdown symbols like #, *, -, ** in your response. Use plain text only.\"\n",
    "        )\n",
    "\n",
    "    # Prepare messages for the AI model\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Send request to LLaMA3 model via Ollama\n",
    "        response = await ollama_client.chat.completions.create(\n",
    "            model=\"llama3:8b\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        notes = response.choices[0].message.content\n",
    "        # Clean any remaining markdown symbols that might have been generated\n",
    "        notes = clean_markdown_symbols(notes)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ollama generation error: {e}\")\n",
    "        return f\"Error generating notes: {e}\"\n",
    "\n",
    "    # Quality control: Evaluate notes and retry if needed\n",
    "    if retries > 0:\n",
    "        evaluation = await evaluate_notes(text_chunk, notes)\n",
    "        if not evaluation.is_acceptable:\n",
    "            print(f\"🔁 Retrying with feedback: {evaluation.feedback}\")\n",
    "            return await generate_notes(text_chunk, retries - 1, evaluation.feedback)\n",
    "        else:\n",
    "            print(\"✅ Notes passed evaluation.\")\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c190e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_markdown_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Comprehensive markdown symbol removal function.\n",
    "    \n",
    "    This function uses regular expressions to systematically remove all markdown\n",
    "    formatting symbols while preserving the actual content.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text containing markdown symbols\n",
    "        \n",
    "    Returns:\n",
    "        str: Clean text without markdown symbols\n",
    "    \"\"\"\n",
    "    # Remove headers (#, ##, ###, etc.)\n",
    "    text = re.sub(r'^#+\\s*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove bold formatting: **bold** becomes bold\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    \n",
    "    # Remove italic formatting: *italic* becomes italic\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)\n",
    "    \n",
    "    # Remove underscore italic: _italic_ becomes italic\n",
    "    text = re.sub(r'_(.*?)_', r'\\1', text)\n",
    "    \n",
    "    # Remove unordered list markers (-, *, +) but keep indentation\n",
    "    text = re.sub(r'^[\\*\\-+]\\s+', '  ', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove numbered list markers (1., 2., etc.) but keep indentation\n",
    "    text = re.sub(r'^\\d+\\.\\s+', '  ', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove blockquote markers (>)\n",
    "    text = re.sub(r'^>\\s+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove inline code markers (`code`)\n",
    "    text = re.sub(r'`{1,3}(.*?)`{1,3}', r'\\1', text)\n",
    "    \n",
    "    # Remove horizontal rules (---, ***)\n",
    "    text = re.sub(r'^[\\*\\-_]{3,}\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Clean up excessive empty lines for better formatting\n",
    "    text = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b73b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_notes(text_chunk: str, notes: str) -> Evaluation:\n",
    "    \"\"\"\n",
    "    Evaluate the quality of generated notes using GPT-4o-mini.\n",
    "    \n",
    "    This function:\n",
    "    1. Sends original text and generated notes to GPT-4o-mini for evaluation\n",
    "    2. Checks for accuracy, clarity, and absence of markdown\n",
    "    3. Returns structured evaluation with feedback\n",
    "    \n",
    "    Args:\n",
    "        text_chunk (str): Original textbook text\n",
    "        notes (str): Generated notes to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation: Structured evaluation result with acceptability and feedback\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are a quality evaluator. Check if the notes correctly and clearly summarize the text \"\n",
    "        \"and are well-structured for PDF format. Also check that they don't contain markdown symbols. \"\n",
    "        \"Respond in JSON with keys: is_acceptable (bool) and feedback (string).\\n\\n\"\n",
    "        f\"--- Original Text ---\\n{text_chunk}\\n\\n\"\n",
    "        f\"--- Notes ---\\n{notes}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Send evaluation request to GPT-4o-mini\n",
    "        response = await gpt_eval_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # Changed to GPT-4o-mini\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},  # Request JSON response for easy parsing\n",
    "        )\n",
    "        # Parse JSON response into Evaluation model\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        return Evaluation(**data)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPT-4o-mini evaluation error: {e}\")\n",
    "        # If evaluation fails, accept the notes to avoid blocking the process\n",
    "        return Evaluation(is_acceptable=True, feedback=f\"Evaluation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cabd87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 2500) -> list:\n",
    "    \"\"\"\n",
    "    Split long text into manageable chunks for processing.\n",
    "    \n",
    "    Large textbooks are broken into smaller chunks because:\n",
    "    - AI models have token limits\n",
    "    - Better quality summaries for focused sections\n",
    "    - Prevents timeout and memory issues\n",
    "    \n",
    "    Args:\n",
    "        text (str): Full textbook text\n",
    "        max_chars (int): Maximum characters per chunk\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93f8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace problematic Unicode characters with ASCII equivalents.\n",
    "    \n",
    "    FPDF has limited Unicode support, so we replace characters that cause issues:\n",
    "    - Bullets, dashes, quotes, mathematical symbols, etc.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text containing potential problematic characters\n",
    "        \n",
    "    Returns:\n",
    "        str: Text with safe ASCII replacements\n",
    "    \"\"\"\n",
    "    # Dictionary mapping Unicode characters to ASCII equivalents\n",
    "    replacements = {\n",
    "        '•': '-',      # bullet to hyphen\n",
    "        '–': '-',      # en dash to hyphen\n",
    "        '—': '-',      # em dash to hyphen\n",
    "        '“': '\"',      # left double quote to straight quote\n",
    "        '”': '\"',      # right double quote to straight quote\n",
    "        '‘': \"'\",      # left single quote to straight quote\n",
    "        '’': \"'\",      # right single quote to straight quote\n",
    "        '…': '...',    # ellipsis to three dots\n",
    "        '→': '->',     # right arrow to ASCII\n",
    "        '←': '<-',     # left arrow to ASCII\n",
    "        '≥': '>=',     # greater than or equal to ASCII\n",
    "        '≤': '<=',     # less than or equal to ASCII\n",
    "        '×': 'x',      # multiplication sign to letter x\n",
    "        '÷': '/',      # division sign to slash\n",
    "        '±': '+/-',    # plus-minus to ASCII representation\n",
    "    }\n",
    "    \n",
    "    # Apply all replacements\n",
    "    for unicode_char, ascii_char in replacements.items():\n",
    "        text = text.replace(unicode_char, ascii_char)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c679c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_file(notes_text: str, source_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert clean text notes into a professionally formatted PDF document.\n",
    "    \n",
    "    This function:\n",
    "    1. Creates a PDF with proper styling and formatting\n",
    "    2. Uses intelligent heading detection\n",
    "    3. Applies consistent typography and spacing\n",
    "    4. Handles different content types (headings, paragraphs, lists)\n",
    "    \n",
    "    Args:\n",
    "        notes_text (str): Clean notes text without markdown\n",
    "        source_filename (str): Original textbook filename for naming output\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the generated PDF file\n",
    "    \"\"\"\n",
    "    # Generate output filename based on source textbook\n",
    "    title = os.path.splitext(os.path.basename(source_filename))[0].replace('_', ' ').title()\n",
    "    output_filename = f\"{os.path.splitext(source_filename)[0]}_notes.pdf\"\n",
    "\n",
    "    # Initialize PDF document with auto page break\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    \n",
    "    # Add first page\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Title section - centered and bold\n",
    "    pdf.set_font(\"helvetica\", \"B\", 16)\n",
    "    pdf.cell(0, 10, f\"Academic Notes: {title}\", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align=\"C\")\n",
    "    pdf.ln(5)\n",
    "    \n",
    "    # Metadata section - italic and centered\n",
    "    pdf.set_font(\"helvetica\", \"I\", 10)\n",
    "    pdf.cell(0, 8, f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align=\"C\")\n",
    "    pdf.ln(15)\n",
    "    \n",
    "    # Process notes content line by line\n",
    "    pdf.set_font(\"helvetica\", \"\", 11)\n",
    "    lines = notes_text.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            pdf.ln(5)  # Add space for empty lines\n",
    "            continue\n",
    "            \n",
    "        # Sanitize line to remove problematic Unicode characters\n",
    "        safe_line = sanitize_text(line)\n",
    "        \n",
    "        # Intelligent heading detection based on text patterns\n",
    "        is_heading = (\n",
    "            safe_line.isupper() or                    # ALL CAPS text\n",
    "            safe_line.endswith(':') or                # Ends with colon\n",
    "            len(safe_line) < 50 and not safe_line.startswith('  ')  # Short line without indentation\n",
    "        )\n",
    "        \n",
    "        # Apply appropriate formatting based on content type\n",
    "        if is_heading and len(safe_line) > 3:\n",
    "            # Main heading - bold and larger font\n",
    "            pdf.set_font(\"helvetica\", \"B\", 14)\n",
    "            pdf.cell(0, 10, safe_line, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_font(\"helvetica\", \"\", 11)\n",
    "            pdf.ln(3)\n",
    "        elif safe_line.startswith('  ') and not safe_line.startswith('   '):\n",
    "            # Sub-heading or major bullet point - bold and medium font\n",
    "            pdf.set_font(\"helvetica\", \"B\", 12)\n",
    "            clean_line = safe_line.strip()\n",
    "            pdf.cell(0, 8, clean_line, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_font(\"helvetica\", \"\", 11)\n",
    "            pdf.ln(2)\n",
    "        elif safe_line.startswith('    ') or safe_line.startswith('   '):\n",
    "            # Indented content (sub-bullet points) - normal font with indentation\n",
    "            pdf.set_font(\"helvetica\", \"\", 11)\n",
    "            clean_line = safe_line.strip()\n",
    "            pdf.cell(10)  # Add indentation\n",
    "            pdf.multi_cell(0, 5, f\"- {clean_line}\")  # Multi-cell for text wrapping\n",
    "            pdf.ln(1)\n",
    "        else:\n",
    "            # Regular paragraph - normal font and multi-cell for wrapping\n",
    "            pdf.set_font(\"helvetica\", \"\", 11)\n",
    "            pdf.multi_cell(0, 5, safe_line)\n",
    "            pdf.ln(2)\n",
    "    \n",
    "    # Add footer with source information\n",
    "    pdf.set_y(-15)\n",
    "    pdf.set_font(\"helvetica\", \"I\", 8)\n",
    "    pdf.cell(0, 10, f\"Generated from: {os.path.basename(source_filename)}\", align=\"C\")\n",
    "    \n",
    "    try:\n",
    "        # Generate PDF file\n",
    "        pdf.output(output_filename)\n",
    "        print(f\"✅ PDF created: {output_filename}\")\n",
    "        return output_filename\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ PDF creation error: {e}\")\n",
    "        # Fallback: Create text file if PDF generation fails\n",
    "        fallback = f\"{os.path.splitext(source_filename)[0]}_notes.txt\"\n",
    "        with open(fallback, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Notes for {title}\\n\")\n",
    "            f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "            f.write(notes_text)\n",
    "        print(f\"Saved fallback text file: {fallback}\")\n",
    "        return fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c008f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_async_in_thread(async_func, *args):\n",
    "    \"\"\"\n",
    "    Run asynchronous functions in a separate thread to avoid event loop conflicts.\n",
    "    \n",
    "    Gradio runs in its own event loop, so we need to run async AI functions\n",
    "    in separate threads to prevent conflicts.\n",
    "    \n",
    "    Args:\n",
    "        async_func: Asynchronous function to execute\n",
    "        *args: Arguments to pass to the function\n",
    "        \n",
    "    Returns:\n",
    "        The result of the async function\n",
    "    \"\"\"\n",
    "    # Create new event loop for this thread\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        # Run the async function and return result\n",
    "        return loop.run_until_complete(async_func(*args))\n",
    "    finally:\n",
    "        # Clean up the event loop\n",
    "        loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0da8f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_textbook_sync(file, progress=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Main textbook processing pipeline - synchronous wrapper for Gradio compatibility.\n",
    "    \n",
    "    This function coordinates the entire process:\n",
    "    1. Text extraction from PDF\n",
    "    2. Chunking for processing\n",
    "    3. AI-powered note generation\n",
    "    4. Quality evaluation\n",
    "    5. PDF creation\n",
    "    \n",
    "    Args:\n",
    "        file: Uploaded PDF file object from Gradio\n",
    "        progress: Gradio progress tracker for UI updates\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Status message and path to generated PDF\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return \"Please upload a textbook to begin.\", None\n",
    "\n",
    "    try:\n",
    "        from PyPDF2 import PdfReader\n",
    "        \n",
    "        pdf_file_path = file.name\n",
    "        reader = PdfReader(pdf_file_path)\n",
    "        num_pages = len(reader.pages)\n",
    "\n",
    "        # Step 1 — Text Extraction\n",
    "        progress(0, desc=\"Step 1/4: Extracting text...\")\n",
    "        full_text = \"\"\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            progress((i + 1) / num_pages, desc=f\"Extracting Page {i + 1}/{num_pages}\")\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                full_text += page_text + \"\\n\"\n",
    "\n",
    "        if not full_text.strip():\n",
    "            return \"⚠️ No text extracted from the PDF.\", None\n",
    "\n",
    "        print(f\"✅ Extracted {len(full_text)} characters from {num_pages} pages.\")\n",
    "\n",
    "        # Step 2 — Text Chunking and Note Generation\n",
    "        chunks = chunk_text(full_text)\n",
    "        num_chunks = len(chunks)\n",
    "        all_notes = []\n",
    "\n",
    "        progress(0, desc=\"Step 2/4: Generating notes...\")\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            progress((i + 1) / num_chunks, desc=f\"Generating Chunk {i + 1}/{num_chunks}\")\n",
    "            # Run async note generation in thread\n",
    "            notes_chunk = run_async_in_thread(generate_notes, chunk)\n",
    "            # Clean any remaining markdown from generated notes\n",
    "            clean_notes = clean_markdown_symbols(notes_chunk)\n",
    "            all_notes.append(clean_notes)\n",
    "\n",
    "        # Combine all notes chunks\n",
    "        combined_notes = \"\\n\\n\".join(all_notes)\n",
    "\n",
    "        # Final cleanup pass for any remaining markdown\n",
    "        combined_notes = clean_markdown_symbols(combined_notes)\n",
    "\n",
    "        # Step 3 — PDF Creation\n",
    "        progress(1, desc=\"Step 3/4: Creating PDF...\")\n",
    "        pdf_output_path = create_pdf_file(combined_notes, pdf_file_path)\n",
    "\n",
    "        # Step 4 — Return Results\n",
    "        if os.path.exists(pdf_output_path):\n",
    "            message = f\"✅ Notes generated successfully!\\n\\n**Saved as:** {os.path.basename(pdf_output_path)}\"\n",
    "            return message, pdf_output_path\n",
    "        else:\n",
    "            return \"❌ PDF generation failed.\", None\n",
    "            \n",
    "    except ImportError:\n",
    "        return \"❌ PyPDF2 not installed. Please install it using: pip install PyPDF2\", None\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error processing PDF: {str(e)}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3fe3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_notes_interface(file, progress=gr.Progress(track_tqdm=True)):\n",
    "    \"\"\"\n",
    "    Gradio interface function - must be synchronous to avoid event loop issues.\n",
    "    \n",
    "    This function is called by Gradio when user uploads a file.\n",
    "    It coordinates the entire processing pipeline.\n",
    "    \n",
    "    Args:\n",
    "        file: Uploaded file from Gradio\n",
    "        progress: Progress tracker for UI updates\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Status message and output file\n",
    "    \"\"\"\n",
    "    if file is not None:\n",
    "        return process_textbook_sync(file, progress)\n",
    "    return \"Please upload a textbook.\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8156c35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpdf2 version: 2.8.5\n"
     ]
    }
   ],
   "source": [
    "def install_dependencies():\n",
    "    \"\"\"\n",
    "    Install required Python packages if not already available.\n",
    "    \n",
    "    This ensures all necessary dependencies are present:\n",
    "    - PyPDF2 for PDF text extraction\n",
    "    - fpdf2 for PDF generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import PyPDF2\n",
    "    except ImportError:\n",
    "        print(\"Installing PyPDF2...\")\n",
    "        os.system(\"pip install PyPDF2\")\n",
    "    \n",
    "    # Check fpdf2 version for compatibility\n",
    "    try:\n",
    "        import fpdf\n",
    "        print(f\"fpdf2 version: {fpdf.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"Installing fpdf2...\")\n",
    "        os.system(\"pip install fpdf2\")\n",
    "\n",
    "# Install dependencies at startup\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a52ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\gradio\\interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Textbook to Notes Generator...\n",
      "📖 Upload a PDF textbook to generate clean summarized notes\n",
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.scope, self.receive, self.send\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\applications.py\", line 1133, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 123, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 109, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 387, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\fastapi\\routing.py\", line 288, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\gradio\\routes.py\", line 1671, in get_upload_progress\n",
      "    await asyncio.wait_for(\n",
      "        file_upload_statuses.is_tracked(upload_id), timeout=3\n",
      "    )\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\tasks.py\", line 507, in wait_for\n",
      "    return await fut\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Upendra\\Git Hub\\Git Hub -- K-Upendra-7\\abcd-agentic-training-vnr-upendra\\AI-Agent-Textbook-Notebook\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 528, in is_tracked\n",
      "    return await self._signals[upload_id].wait()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Upendra\\Softwares\\Python313\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x000001BC88B34F50 [unset]> is bound to a different event loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 19920 characters from 11 pages.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on tokens per min (TPM): Limit 100000, Used 99098, Requested 1076. Please try again in 1h15m10.08s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on tokens per min (TPM): Limit 100000, Used 99078, Requested 1173. Please try again in 1h48m25.92s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "⚠️ GPT-4o-mini evaluation error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-MkjmLPCmCH96jd8YXEY5SEUP on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "✅ Notes passed evaluation.\n",
      "✅ PDF created: C:\\Users\\kolla\\AppData\\Local\\Temp\\gradio\\9d1f585023bbee10a956ef450312e39e0d4bec0d7c7c4dfda6190eb8846fa20d\\Textbook_notes.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create the Gradio web interface\n",
    "iface = gr.Interface(\n",
    "    fn=create_notes_interface,  # Main processing function\n",
    "    inputs=gr.File(label=\"📘 Upload Textbook (PDF)\"),  # File upload input\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"🧾 Status / Summary\"),  # Status message output\n",
    "        gr.File(label=\"📥 Download Generated Notes (.pdf)\")  # Downloadable PDF output\n",
    "    ],\n",
    "    title=\"AI Textbook → Notebook Notes Generator\",\n",
    "    description=(\n",
    "        \"Upload any textbook (PDF). The local LLaMA 3 (8B) model summarizes it into clean academic notes \"\n",
    "        \"without markdown symbols. GPT-4o-mini evaluates quality, and the output is auto-saved as a clean PDF.\"\n",
    "    ),\n",
    "    allow_flagging=\"never\"  # Disable Gradio's flagging feature\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Startup message and launch the web interface\n",
    "    print(\"🚀 Starting Textbook to Notes Generator...\")\n",
    "    print(\"📖 Upload a PDF textbook to generate clean summarized notes\")\n",
    "    \n",
    "    # Launch Gradio interface\n",
    "    iface.launch(\n",
    "        server_name=\"127.0.0.1\",  # Localhost only for security\n",
    "        share=False,              # Don't create public link\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
