{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Textbook Notes Generator v4.0 (Fixed)\n",
        "\n",
        "This application transforms textbook PDFs into beautifully formatted study notes with executive summaries using AI.\n",
        "\n",
        "## Features:\n",
        "- **PDF Text Extraction**: Extract text from textbooks using PyMuPDF\n",
        "- **AI Note Generation**: Generate structured notes using Ollama (llama3:8b)\n",
        "- **Quality Evaluation**: Evaluate note quality using Gemini AI with retry logic\n",
        "- **Executive Summary**: Create high-level summaries of all content\n",
        "- **Professional PDF Output**: Generate beautifully formatted PDF notes\n",
        "- **Progress Tracking**: Real-time processing status updates\n",
        "\n",
        "## Requirements:\n",
        "- Python 3.8+\n",
        "- Ollama running with llama3:8b model\n",
        "- OpenAI API Key for Gemini access\n",
        "- Google API Key (for Gemini)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (5.33.1)\n",
            "Requirement already satisfied: PyMuPDF in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (1.26.5)\n",
            "Requirement already satisfied: openai in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (1.85.0)\n",
            "Requirement already satisfied: pydantic in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (2.11.5)\n",
            "Requirement already satisfied: fpdf2 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (2.8.4)\n",
            "Requirement already satisfied: python-dotenv in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: aiofiles in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: audioop-lts<1.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.2.2)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.3 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (1.10.3)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.32.4)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (2.3.0)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (2.3.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydub in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio-client==1.10.3->gradio) (2025.5.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from gradio-client==1.10.3->gradio) (14.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: certifi in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: defusedxml in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from fpdf2) (4.60.1)\n",
            "Requirement already satisfied: colorama in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: filelock in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: psutil in c:\\upendra\\git hub\\git hub -- k-upendra-7\\abcd-agentic-training-vnr-upendra\\session-04&05\\textbook-notebook-agent\\.venv\\lib\\site-packages (7.0.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install gradio PyMuPDF openai pydantic fpdf2 python-dotenv aiofiles\n",
        "\n",
        "# For system diagnostics (optional)\n",
        "!pip install psutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Create a `.env` file in your working directory with your API keys:\n",
        "```\n",
        "OPENAI_API_KEY=your_openai_key_here\n",
        "GOOGLE_API_KEY=your_google_key_here\n",
        "```\n",
        "\n",
        "Make sure Ollama is running:\n",
        "```bash\n",
        "ollama serve\n",
        "ollama pull llama3:8b\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… AI Textbook Notes Generator (Fixed) v4.0 initialized\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import textwrap\n",
        "import asyncio\n",
        "import fitz  # PyMuPDF\n",
        "import sys\n",
        "import tempfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "from openai import AsyncOpenAI\n",
        "from pydantic import BaseModel\n",
        "from fpdf import FPDF\n",
        "from typing import Optional, Tuple, List\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Version info\n",
        "VERSION = \"4.0\"\n",
        "APP_NAME = \"AI Textbook Notes Generator (Fixed)\"\n",
        "\n",
        "print(f\"âœ… {APP_NAME} v{VERSION} initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT SETUP & VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "def load_environment():\n",
        "    \"\"\"Load and validate environment configuration\"\"\"\n",
        "    load_dotenv(override=True)\n",
        "    \n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    \n",
        "    if not openai_api_key:\n",
        "        print(\"âŒ OPENAI_API_KEY not found in environment\")\n",
        "        return False, None, None\n",
        "    \n",
        "    if not google_api_key:\n",
        "        print(\"âŒ GOOGLE_API_KEY not found in environment\")  \n",
        "        return False, None, None\n",
        "    \n",
        "    print(f\"âœ… OpenAI API Key found: {openai_api_key[:8]}...\")\n",
        "    print(f\"âœ… Google API Key found: {google_api_key[:8]}...\")\n",
        "    \n",
        "    return True, openai_api_key, google_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# API CLIENTS SETUP\n",
        "# =============================================================================\n",
        "\n",
        "def setup_api_clients(google_api_key):\n",
        "    \"\"\"Setup Ollama and Gemini API clients\"\"\"\n",
        "    try:\n",
        "        # Ollama client for note generation\n",
        "        ollama_client = AsyncOpenAI(\n",
        "            base_url=\"http://localhost:11434/v1\",\n",
        "            api_key=\"ollama\"\n",
        "        )\n",
        "        \n",
        "        # Gemini client for evaluation and summary\n",
        "        gemini_client = AsyncOpenAI(\n",
        "            api_key=google_api_key,\n",
        "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "        )\n",
        "        \n",
        "        return ollama_client, gemini_client\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to setup API clients: {e}\")\n",
        "        return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATA MODELS\n",
        "# =============================================================================\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    \"\"\"Evaluation model for note quality assessment\"\"\"\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n",
        "    clarity_score: int  # Score from 1-5\n",
        "    accuracy_score: int # Score from 1-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TEXT PROCESSING UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def chunk_text(text: str, max_chars: int = 2500):\n",
        "    \"\"\"Split text into manageable chunks for processing\"\"\"\n",
        "    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)\n",
        "\n",
        "def validate_file_upload(file) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Validate uploaded file and return appropriate path or error\"\"\"\n",
        "    if file is None:\n",
        "        return None, \"âŒ No file uploaded. Please select a PDF file.\"\n",
        "    \n",
        "    try:\n",
        "        # Handle both file object and string path\n",
        "        if hasattr(file, 'name'):\n",
        "            file_path = file.name\n",
        "        else:\n",
        "            file_path = str(file)\n",
        "            \n",
        "        # Check file existence\n",
        "        if not os.path.exists(file_path):\n",
        "            return None, f\"âŒ File not found: {file_path}\"\n",
        "            \n",
        "        # Check file extension\n",
        "        if not file_path.lower().endswith('.pdf'):\n",
        "            return None, f\"âŒ File must be a PDF. Received: {file_path}\"\n",
        "            \n",
        "        # Check file size\n",
        "        try:\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            if file_size == 0:\n",
        "                return None, \"âŒ File is empty.\"\n",
        "            if file_size > 50 * 1024 * 1024:  # 50MB limit\n",
        "                return None, \"âŒ File too large. Maximum size is 50MB.\"\n",
        "        except OSError:\n",
        "            pass\n",
        "            \n",
        "        return file_path, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Error accessing file: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PDF TEXT EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "async def extract_text_from_pdf(file_path: str, progress_callback=None):\n",
        "    \"\"\"Extract text content from PDF file using PyMuPDF\"\"\"\n",
        "    if progress_callback:\n",
        "        progress_callback(0.1, \"Initializing PDF extraction...\")\n",
        "    \n",
        "    try:\n",
        "        doc = fitz.open(file_path)\n",
        "        num_pages = len(doc)\n",
        "        \n",
        "        if num_pages == 0:\n",
        "            return None, \"âŒ PDF appears to be empty or corrupted.\"\n",
        "        \n",
        "        full_text = \"\"\n",
        "        for i, page in enumerate(doc):\n",
        "            if progress_callback:\n",
        "                progress = 0.1 + (i / num_pages) * 0.3  # 10% to 40% for extraction\n",
        "                progress_callback(progress, f\"Extracting from Page {i + 1}/{num_pages}\")\n",
        "            \n",
        "            page_text = page.get_text()\n",
        "            if page_text.strip():\n",
        "                full_text += page_text + \"\\n\"\n",
        "        \n",
        "        doc.close()\n",
        "        \n",
        "        if not full_text.strip():\n",
        "            return None, \"âŒ No readable text found in PDF. Ensure the PDF contains extractable text.\"\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(0.4, f\"Text extraction complete. {len(full_text)} characters found.\")\n",
        "            \n",
        "        return full_text, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Error extracting text from PDF: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# AI NOTE GENERATION\n",
        "# =============================================================================\n",
        "\n",
        "async def generate_notes_with_retry(ollama_client, text_chunk: str, retries: int = 2, feedback: str = \"\") -> str:\n",
        "    \"\"\"Generate structured notes with self-correction\"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are an expert academic assistant. \"\n",
        "        \"Read the provided text and produce well-organized, clear Markdown notes. \"\n",
        "        \"Focus on key concepts, definitions, and main ideas. \"\n",
        "        \"Keep the language simple but precise. \"\n",
        "        \"Structure the notes with clear headings and bullet points.\"\n",
        "    )\n",
        "\n",
        "    if feedback:\n",
        "        user_prompt = (\n",
        "            f\"The previous notes were not acceptable. Improve them using this feedback:\\n\"\n",
        "            f\"{feedback}\\n\\nOriginal Text:\\n{text_chunk}\"\n",
        "        )\n",
        "    else:\n",
        "        user_prompt = f\"Generate concise academic notes for the following text:\\n{text_chunk}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = await ollama_client.chat.completions.create(\n",
        "            model=\"llama3:8b\",\n",
        "            messages=messages,\n",
        "            timeout=60  # 1 minute timeout\n",
        "        )\n",
        "        notes = response.choices[0].message.content\n",
        "        return notes\n",
        "        \n",
        "    except asyncio.TimeoutError:\n",
        "        return f\"Error: Generation timeout for this chunk.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error generating notes: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def evaluate_notes_quality(gemini_client, text_chunk: str, notes: str) -> Evaluation:\n",
        "    \"\"\"Evaluate generated notes using Gemini\"\"\"\n",
        "    prompt = (\n",
        "        \"You are a strict quality assurance evaluator. Assess the provided notes \"\n",
        "        \"based on their accuracy (do they match the original text?), \"\n",
        "        \"clarity (are they easy to understand?), and \"\n",
        "        \"completeness (did they miss key concepts from the text?). \"\n",
        "        \"Return a JSON object with four keys only:\\n\"\n",
        "        \"1. is_acceptable (boolean): True if the notes are high quality, False otherwise.\\n\"\n",
        "        \"2. feedback (string): Specific, actionable feedback for improvement.\\n\"\n",
        "        \"3. clarity_score (int): A score from 1 (unclear) to 5 (very clear).\\n\"\n",
        "        \"4. accuracy_score (int): A score from 1 (inaccurate) to 5 (very accurate).\\n\\n\"\n",
        "        f\"--- Original Text ---\\n{text_chunk}\\n\\n\"\n",
        "        f\"--- Notes ---\\n{notes}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await gemini_client.chat.completions.create(\n",
        "            model=\"gemini-2.0-flash-exp\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "            timeout=30  # 30 second timeout\n",
        "        )\n",
        "\n",
        "        data = json.loads(response.choices[0].message.content)\n",
        "        return Evaluation(**data)\n",
        "\n",
        "    except asyncio.TimeoutError:\n",
        "        print(\"âš ï¸  Note evaluation timeout - accepting current quality\")\n",
        "        return Evaluation(\n",
        "            is_acceptable=True,\n",
        "            feedback=\"Evaluation timeout - accepted current quality\",\n",
        "            clarity_score=4,\n",
        "            accuracy_score=4\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Note evaluation error: {e}\")\n",
        "        return Evaluation(\n",
        "            is_acceptable=True,\n",
        "            feedback=f\"Evaluation failed: {e}\",\n",
        "            clarity_score=4,\n",
        "            accuracy_score=4\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def generate_final_summary(gemini_client, all_notes: str) -> str:\n",
        "    \"\"\"Generate executive summary using Gemini\"\"\"\n",
        "    prompt = (\n",
        "        \"You are an expert academic summarizer. \"\n",
        "        \"Read all the provided notes (which were generated from a textbook) \"\n",
        "        \"and generate a concise, high-level executive summary. \"\n",
        "        \"This summary should capture the main themes, key takeaways, and \"\n",
        "        \"overall structure of the content. Output in clean Markdown.\"\n",
        "        f\"\\n\\n--- All Notes ---\\n{all_notes}\"\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        response = await gemini_client.chat.completions.create(\n",
        "            model=\"gemini-2.0-flash-exp\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            timeout=45  # 45 second timeout\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except asyncio.TimeoutError:\n",
        "        return \"Executive Summary (Generation timeout - providing basic summary). This textbook covers important concepts and principles that form the foundation of the subject matter.\"\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Executive summary error: {e}\")\n",
        "        return f\"Executive Summary (Generation failed: {e}). This appears to be an academic text covering various important concepts.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PDF CREATION WITH PROFESSIONAL STYLING\n",
        "# =============================================================================\n",
        "\n",
        "class StyledPDF(FPDF):\n",
        "    \"\"\"Enhanced PDF class with professional styling\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.set_auto_page_break(auto=True, margin=15)\n",
        "        \n",
        "    def header(self):\n",
        "        \"\"\"Header with page number\"\"\"\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.set_text_color(128, 128, 128)\n",
        "        self.cell(0, 10, f'{APP_NAME}', 0, 0, 'C')\n",
        "        self.ln(5)\n",
        "        \n",
        "    def footer(self):\n",
        "        \"\"\"Footer with page numbers\"\"\"\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.set_text_color(128, 128, 128)\n",
        "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
        "        \n",
        "    def create_title_page(self, title: str):\n",
        "        \"\"\"Create a professional title page\"\"\"\n",
        "        self.add_page()\n",
        "        \n",
        "        # Main title\n",
        "        self.set_font('Arial', 'B', 24)\n",
        "        self.set_text_color(0, 51, 102)\n",
        "        self.ln(60)\n",
        "        \n",
        "        # Center the title\n",
        "        title_lines = self.split_text(title, 180)\n",
        "        for line in title_lines:\n",
        "            self.cell(0, 15, line, 0, 1, 'C')\n",
        "        \n",
        "        self.ln(20)\n",
        "        \n",
        "        # Subtitle\n",
        "        self.set_font('Arial', 'I', 14)\n",
        "        self.set_text_color(102, 102, 102)\n",
        "        subtitle_lines = self.split_text(\"Generated by AI Textbook Notes Generator\", 180)\n",
        "        for line in subtitle_lines:\n",
        "            self.cell(0, 10, line, 0, 1, 'C')\n",
        "        \n",
        "        self.ln(20)\n",
        "        \n",
        "        # Generation info\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.set_text_color(128, 128, 128)\n",
        "        date_str = datetime.now().strftime(\"%B %d, %Y\")\n",
        "        info_text = f\"Generated on {date_str}\"\n",
        "        self.cell(0, 8, info_text, 0, 1, 'C')\n",
        "        \n",
        "        self.ln(40)\n",
        "        \n",
        "        # Decorative border\n",
        "        self.set_line_width(2)\n",
        "        self.set_draw_color(0, 51, 102)\n",
        "        self.line(15, self.get_y(), 195, self.get_y())\n",
        "\n",
        "    def split_text(self, text: str, max_width: int) -> List[str]:\n",
        "        \"\"\"Split text to fit within max_width\"\"\"\n",
        "        words = text.split()\n",
        "        lines = []\n",
        "        current_line = \"\"\n",
        "        \n",
        "        for word in words:\n",
        "            test_line = current_line + (\" \" if current_line else \"\") + word\n",
        "            if self.get_string_width(test_line) <= max_width:\n",
        "                current_line = test_line\n",
        "            else:\n",
        "                if current_line:\n",
        "                    lines.append(current_line)\n",
        "                current_line = word\n",
        "                \n",
        "        if current_line:\n",
        "            lines.append(current_line)\n",
        "            \n",
        "        return lines\n",
        "\n",
        "    def add_section_header(self, title: str):\n",
        "        \"\"\"Add a styled section header\"\"\"\n",
        "        self.ln(10)\n",
        "        self.set_font('Arial', 'B', 16)\n",
        "        self.set_text_color(0, 51, 102)\n",
        "        self.cell(0, 12, title, 0, 1, 'L')\n",
        "        \n",
        "        # Decorative underline\n",
        "        self.set_line_width(0.8)\n",
        "        self.set_draw_color(0, 51, 102)\n",
        "        self.line(15, self.get_y(), 100, self.get_y())\n",
        "        self.ln(8)\n",
        "\n",
        "    def add_content_line(self, text: str, indent: int = 0):\n",
        "        \"\"\"Add a line of content with proper formatting\"\"\"\n",
        "        self.set_font('Arial', '', 11)\n",
        "        self.set_text_color(0, 0, 0)\n",
        "        \n",
        "        # Handle bullet points\n",
        "        if text.strip().startswith('â€¢') or text.strip().startswith('-'):\n",
        "            bullet = text.strip()[0]\n",
        "            content = text.strip()[1:].strip()\n",
        "            \n",
        "            if indent > 0:\n",
        "                self.cell(indent, 6, '', 0, 0, 'L')\n",
        "            self.cell(10, 6, bullet, 0, 0, 'L')\n",
        "            \n",
        "            lines = self.split_text(content, 180 - indent - 10)\n",
        "            if lines:\n",
        "                self.cell(0, 6, lines[0], 0, 1, 'L')\n",
        "                for line in lines[1:]:\n",
        "                    if indent > 0:\n",
        "                        self.cell(indent, 6, '', 0, 0, 'L')\n",
        "                    self.cell(10, 6, '', 0, 0, 'L')\n",
        "                    self.cell(0, 6, line, 0, 1, 'L')\n",
        "        else:\n",
        "            # Regular text with word wrapping\n",
        "            lines = self.split_text(text, 180 - indent)\n",
        "            if lines:\n",
        "                if len(lines) == 1:\n",
        "                    if indent > 0:\n",
        "                        self.cell(indent, 6, '', 0, 0, 'L')\n",
        "                    self.cell(0, 6, lines[0], 0, 1, 'L')\n",
        "                else:\n",
        "                    if indent > 0:\n",
        "                        self.cell(indent, 6, '', 0, 0, 'L')\n",
        "                    self.cell(0, 6, lines[0], 0, 1, 'L')\n",
        "                    for line in lines[1:]:\n",
        "                        if indent > 0:\n",
        "                            self.cell(indent, 6, '', 0, 0, 'L')\n",
        "                        self.cell(0, 6, line, 0, 1, 'L')\n",
        "\n",
        "    def process_markdown(self, markdown_content: str):\n",
        "        \"\"\"Process markdown content and add to PDF\"\"\"\n",
        "        lines = markdown_content.split('\\n')\n",
        "        \n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            \n",
        "            if not line:\n",
        "                # Empty line\n",
        "                self.ln(4)\n",
        "                continue\n",
        "                \n",
        "            if line.startswith('# '):\n",
        "                # Main heading\n",
        "                title = line[2:].strip()\n",
        "                self.add_section_header(title)\n",
        "                \n",
        "            elif line.startswith('## '):\n",
        "                # Subheading\n",
        "                title = line[3:].strip()\n",
        "                self.set_font('Arial', 'B', 14)\n",
        "                self.set_text_color(51, 102, 153)\n",
        "                self.ln(5)\n",
        "                self.cell(0, 10, title, 0, 1, 'L')\n",
        "                self.set_line_width(0.5)\n",
        "                self.set_draw_color(200, 200, 200)\n",
        "                self.line(15, self.get_y(), 100, self.get_y())\n",
        "                self.ln(8)\n",
        "                \n",
        "            elif line.startswith('### '):\n",
        "                # Sub-subheading\n",
        "                title = line[4:].strip()\n",
        "                self.set_font('Arial', 'B', 12)\n",
        "                self.set_text_color(102, 102, 153)\n",
        "                self.ln(3)\n",
        "                self.cell(0, 8, title, 0, 1, 'L')\n",
        "                self.ln(3)\n",
        "                \n",
        "            elif line.startswith('- ') or line.startswith('â€¢ '):\n",
        "                # Bullet point\n",
        "                content = line[2:].strip()\n",
        "                self.add_content_line('â€¢ ' + content, indent=15)\n",
        "                \n",
        "            else:\n",
        "                # Regular paragraph\n",
        "                if line:\n",
        "                    self.add_content_line(line)\n",
        "\n",
        "def create_styled_pdf(notes_markdown: str, source_filename: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Create a beautifully formatted PDF from notes\"\"\"\n",
        "    try:\n",
        "        # Generate output filename\n",
        "        base_name = os.path.splitext(os.path.basename(source_filename))[0]\n",
        "        output_filename = f\"{base_name}_ai_notes.pdf\"\n",
        "        \n",
        "        # Create PDF\n",
        "        pdf = StyledPDF()\n",
        "        \n",
        "        # Title\n",
        "        title = base_name.replace('_', ' ').title()\n",
        "        pdf.create_title_page(title)\n",
        "        \n",
        "        # Process content\n",
        "        pdf.process_markdown(notes_markdown)\n",
        "        \n",
        "        # Save\n",
        "        pdf.output(output_filename)\n",
        "        \n",
        "        print(f\"âœ… PDF created successfully: {output_filename}\")\n",
        "        return output_filename, None\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Error creating PDF: {e}\"\n",
        "        print(error_msg)\n",
        "        return None, error_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MAIN PROCESSING PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "async def process_textbook_complete(file, progress_callback=None) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"Complete processing pipeline from PDF upload to formatted notes\"\"\"\n",
        "    \n",
        "    # Step 1: File validation\n",
        "    if progress_callback:\n",
        "        progress_callback(0.05, \"Validating file...\")\n",
        "    \n",
        "    file_path, error = validate_file_upload(file)\n",
        "    if error:\n",
        "        return None, error\n",
        "    if progress_callback:\n",
        "        progress_callback(0.1, \"File validated successfully\")\n",
        "    \n",
        "    # Step 2: Environment setup\n",
        "    env_ok, openai_key, google_key = load_environment()\n",
        "    if not env_ok:\n",
        "        return None, \"Environment setup failed. Please check your .env file.\"\n",
        "    \n",
        "    # Step 3: API client setup\n",
        "    if progress_callback:\n",
        "        progress_callback(0.15, \"Setting up API clients...\")\n",
        "    \n",
        "    ollama_client, gemini_client = setup_api_clients(google_key)\n",
        "    if not ollama_client or not gemini_client:\n",
        "        return None, \"Failed to setup API clients. Please check your internet connection and API keys.\"\n",
        "    if progress_callback:\n",
        "        progress_callback(0.2, \"API clients ready\")\n",
        "    \n",
        "    # Step 4: Extract text from PDF\n",
        "    full_text, error = await extract_text_from_pdf(file_path, progress_callback)\n",
        "    if error:\n",
        "        return None, error\n",
        "    \n",
        "    if progress_callback:\n",
        "        progress_callback(0.4, \"Text extraction complete\")\n",
        "    \n",
        "    # Step 5: Chunk text and generate notes\n",
        "    if progress_callback:\n",
        "        progress_callback(0.45, \"Starting note generation...\")\n",
        "    \n",
        "    chunks = chunk_text(full_text)\n",
        "    all_notes = []\n",
        "    num_chunks = len(chunks)\n",
        "    \n",
        "    if progress_callback:\n",
        "        progress_callback(0.5, f\"Processing {num_chunks} text chunks...\")\n",
        "    \n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if progress_callback:\n",
        "            progress = 0.5 + (i / num_chunks) * 0.3  # 50% to 80%\n",
        "            progress_callback(progress, f\"Generating notes - Chunk {i + 1}/{num_chunks}\")\n",
        "        \n",
        "        try:\n",
        "            # Generate notes with retry logic\n",
        "            notes_chunk = await generate_notes_with_retry(ollama_client, chunk)\n",
        "            \n",
        "            # Evaluate quality\n",
        "            evaluation = await evaluate_notes_quality(gemini_client, chunk, notes_chunk)\n",
        "            \n",
        "            # Retry if necessary\n",
        "            if not evaluation.is_acceptable or (evaluation.clarity_score < 3 or evaluation.accuracy_score < 3):\n",
        "                print(f\"ðŸ”„ Retrying chunk {i + 1} with feedback: {evaluation.feedback}\")\n",
        "                notes_chunk = await generate_notes_with_retry(ollama_client, chunk, retries=1, feedback=evaluation.feedback)\n",
        "            \n",
        "            all_notes.append(notes_chunk)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Error processing chunk {i + 1}: {e}\")\n",
        "            all_notes.append(f\"[Note: Error processing this section - {str(e)}]\")\n",
        "    \n",
        "    if progress_callback:\n",
        "        progress_callback(0.8, \"Note generation complete\")\n",
        "    \n",
        "    # Step 6: Generate executive summary\n",
        "    if progress_callback:\n",
        "        progress_callback(0.82, \"Generating executive summary...\")\n",
        "    \n",
        "    combined_notes = \"\\n\\n---\\n\\n\".join(all_notes)\n",
        "    final_summary = await generate_final_summary(gemini_client, combined_notes)\n",
        "    \n",
        "    if progress_callback:\n",
        "        progress_callback(0.88, \"Executive summary complete\")\n",
        "    \n",
        "    # Step 7: Create final markdown\n",
        "    final_markdown = f\"# Executive Summary\\n\\n{final_summary}\\n\\n---\\n\\n# Detailed Notes\\n\\n{combined_notes}\"\n",
        "    \n",
        "    # Step 8: Create styled PDF\n",
        "    if progress_callback:\n",
        "        progress_callback(0.9, \"Creating beautiful PDF...\")\n",
        "    \n",
        "    pdf_path, error = create_styled_pdf(final_markdown, file_path)\n",
        "    if error:\n",
        "        return None, error\n",
        "    \n",
        "    if progress_callback:\n",
        "        progress_callback(1.0, \"Processing complete!\")\n",
        "    \n",
        "    return pdf_path, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DIAGNOSTIC FUNCTIONS (Fixed for Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "def run_system_diagnostics_sync():\n",
        "    \"\"\"Synchronous version of system diagnostics for notebook\"\"\"\n",
        "    print(\"ðŸ©º Running System Diagnostics...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    issues = []\n",
        "    \n",
        "    # Check Python version\n",
        "    print(f\"âœ… Python version: {sys.version}\")\n",
        "    \n",
        "    # Check required packages\n",
        "    required_packages = [\n",
        "        'gradio', 'fitz', 'openai', 'pydantic', 'fpdf', \n",
        "        'dotenv', 'asyncio', 'pathlib'\n",
        "    ]\n",
        "    \n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "            print(f\"âœ… {package} - available\")\n",
        "        except ImportError:\n",
        "            print(f\"âŒ {package} - MISSING\")\n",
        "            # Handle special case for python-dotenv\n",
        "            if package == 'dotenv':\n",
        "                issues.append(\"Install python-dotenv: pip install python-dotenv\")\n",
        "            else:\n",
        "                issues.append(f\"Install {package}: pip install {package}\")\n",
        "    \n",
        "    # Check environment\n",
        "    env_ok, openai_key, google_key = load_environment()\n",
        "    if not env_ok:\n",
        "        issues.append(\"Configure OPENAI_API_KEY and GOOGLE_API_KEY in .env file\")\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    if not issues:\n",
        "        print(\"ðŸŽ‰ All checks passed! System ready to use.\")\n",
        "        print(\"ðŸ’¡ Note: Ollama connection will be tested during actual processing.\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"âš ï¸  Issues found:\")\n",
        "        for i, issue in enumerate(issues, 1):\n",
        "            print(f\"   {i}. {issue}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# GRADIO INTERFACE (Fixed)\n",
        "# =============================================================================\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"Create the Gradio interface\"\"\"\n",
        "    \n",
        "    def process_with_progress(file, progress=gr.Progress(track_tqdm=True)):\n",
        "        \"\"\"Wrapper function with progress tracking - handles async in notebook\"\"\"\n",
        "        import asyncio\n",
        "        \n",
        "        def progress_callback(value, desc):\n",
        "            progress(value, desc=desc)\n",
        "            \n",
        "        try:\n",
        "            # Check if we're in an event loop\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                # We're in a notebook - create a new task\n",
        "                import concurrent.futures\n",
        "                import threading\n",
        "                \n",
        "                def run_async():\n",
        "                    new_loop = asyncio.new_event_loop()\n",
        "                    asyncio.set_event_loop(new_loop)\n",
        "                    try:\n",
        "                        return new_loop.run_until_complete(process_textbook_complete(file, progress_callback))\n",
        "                    finally:\n",
        "                        new_loop.close()\n",
        "                \n",
        "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                    future = executor.submit(run_async)\n",
        "                    return future.result()\n",
        "            else:\n",
        "                # No event loop running - use asyncio.run\n",
        "                return asyncio.run(process_textbook_complete(file, progress_callback))\n",
        "        except RuntimeError:\n",
        "            # No event loop at all\n",
        "            return asyncio.run(process_textbook_complete(file, progress_callback))\n",
        "    \n",
        "    # Custom CSS for better appearance\n",
        "    css = \"\"\"\n",
        "    .gradio-container { \n",
        "        max-width: 900px !important; \n",
        "        margin: auto !important; \n",
        "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "    }\n",
        "    .title { \n",
        "        text-align: center; \n",
        "        color: #003366; \n",
        "        font-size: 32px; \n",
        "        margin-bottom: 15px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .description { \n",
        "        text-align: center; \n",
        "        color: #666; \n",
        "        margin-bottom: 25px;\n",
        "        font-size: 16px;\n",
        "    }\n",
        "    .status-info {\n",
        "        background-color: #f8f9fa;\n",
        "        border: 1px solid #dee2e6;\n",
        "        border-radius: 8px;\n",
        "        padding: 15px;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        import gradio as gr\n",
        "        \n",
        "        with gr.Blocks(css=css) as interface:\n",
        "            gr.HTML(f\"\"\"\n",
        "            <div class=\"title\">{APP_NAME} v{VERSION}</div>\n",
        "            <div class=\"description\">\n",
        "                Transform any textbook PDF into beautifully formatted study notes with executive summary.<br>\n",
        "                Upload your textbook â†’ Get professional PDF notes with styling, TOC, and quality evaluation.\n",
        "            </div>\n",
        "            \"\"\")\n",
        "            \n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    file_input = gr.File(\n",
        "                        label=\"ðŸ“– Upload Your Textbook (PDF)\", \n",
        "                        file_types=[\".pdf\"]\n",
        "                    )\n",
        "                    \n",
        "                    gr.HTML(\"\"\"\n",
        "                    <div class=\"status-info\">\n",
        "                        <strong>ðŸ“‹ Requirements:</strong><br>\n",
        "                        â€¢ PDF must contain extractable text (not just images)<br>\n",
        "                        â€¢ File size: Max 50MB<br>\n",
        "                        â€¢ Ensure Ollama is running with llama3:8b model<br>\n",
        "                        â€¢ Configure OPENAI_API_KEY and GOOGLE_API_KEY in .env file\n",
        "                    </div>\n",
        "                    \"\"\")\n",
        "                    \n",
        "                with gr.Column(scale=1):\n",
        "                    output_file = gr.File(\n",
        "                        label=\"ðŸ“¥ Download Generated Notes (.pdf)\"\n",
        "                    )\n",
        "            \n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"ðŸš€ Generate Beautiful Notes\", variant=\"primary\", size=\"lg\")\n",
        "                clear_btn = gr.Button(\"ðŸ—‘ï¸ Clear\", variant=\"secondary\")\n",
        "            \n",
        "            # Status display\n",
        "            status_output = gr.Textbox(\n",
        "                label=\"ðŸ“Š Current Status\", \n",
        "                value=\"Ready to process your textbook\",\n",
        "                interactive=False,\n",
        "                lines=3\n",
        "            )\n",
        "            \n",
        "            # Connect events\n",
        "            submit_btn.click(\n",
        "                fn=process_with_progress,\n",
        "                inputs=[file_input],\n",
        "                outputs=[output_file],\n",
        "                show_progress=\"full\"\n",
        "            ).then(\n",
        "                fn=lambda: \"âœ… Processing complete! Download your notes.\",\n",
        "                outputs=[status_output]\n",
        "            )\n",
        "            \n",
        "            clear_btn.click(\n",
        "                fn=lambda: (None, \"Ready to process your textbook\"),\n",
        "                outputs=[output_file, status_output]\n",
        "            )\n",
        "        \n",
        "        return interface\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to create Gradio interface: {e}\")\n",
        "        print(\"ðŸ’¡ Make sure gradio is installed: pip install gradio\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MAIN APPLICATION (Fixed for Notebook)\n",
        "# =============================================================================\n",
        "\n",
        "def launch_app():\n",
        "    \"\"\"Launch the application - fixed for notebook environment\"\"\"\n",
        "    print(f\"ðŸš€ {APP_NAME} v{VERSION}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"This notebook application includes:\")\n",
        "    print(\"â€¢ Professional PDF generation with styling\")\n",
        "    print(\"â€¢ Built-in diagnostics and error handling\")\n",
        "    print(\"â€¢ Cross-platform file support\")\n",
        "    print(\"â€¢ Automatic quality evaluation and retry logic\")\n",
        "    print(\"â€¢ Executive summary generation\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Run basic diagnostics\n",
        "    try:\n",
        "        if not run_system_diagnostics_sync():\n",
        "            print(\"\\nâŒ System not ready. Please fix the issues above before continuing.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Diagnostics failed: {e}\")\n",
        "        print(\"ðŸ’¡ Continuing anyway - application will provide runtime checks.\")\n",
        "    \n",
        "    print(f\"\\nðŸŒ Starting {APP_NAME}...\")\n",
        "    print(\"ðŸ“ Interface will be available below\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Create and launch interface\n",
        "        interface = create_interface()\n",
        "        if interface:\n",
        "            interface.launch(\n",
        "                server_name=\"127.0.0.1\", \n",
        "                share=False, \n",
        "                show_error=True,\n",
        "                quiet=False,\n",
        "                inbrowser=True  # Open in browser automatically\n",
        "            )\n",
        "            return True\n",
        "        else:\n",
        "            print(\"âŒ Failed to create interface\")\n",
        "            return False\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nðŸ‘‹ Shutting down gracefully...\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to start application: {e}\")\n",
        "        print(\"\\nðŸ”§ Troubleshooting:\")\n",
        "        print(\"â€¢ Ensure all dependencies are installed\")\n",
        "        print(\"â€¢ Check if port 7860 is available\")\n",
        "        print(\"â€¢ Verify Ollama is running: ollama serve\")\n",
        "        print(\"â€¢ Check your API keys in .env file\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Quick System Check\n",
        "\n",
        "Run this cell to check if your system is ready:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running quick diagnostics...\n",
            "ðŸ©º Running System Diagnostics...\n",
            "============================================================\n",
            "âœ… Python version: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
            "âœ… gradio - available\n",
            "âœ… fitz - available\n",
            "âœ… openai - available\n",
            "âœ… pydantic - available\n",
            "âœ… fpdf - available\n",
            "âœ… dotenv - available\n",
            "âœ… asyncio - available\n",
            "âœ… pathlib - available\n",
            "âœ… OpenAI API Key found: sk-proj-...\n",
            "âœ… Google API Key found: AIzaSyDn...\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ All checks passed! System ready to use.\n",
            "ðŸ’¡ Note: Ollama connection will be tested during actual processing.\n",
            "\n",
            "âœ… System is ready! Run launch_app() to start the application.\n"
          ]
        }
      ],
      "source": [
        "# Quick system check\n",
        "print(\"Running quick diagnostics...\")\n",
        "result = run_system_diagnostics_sync()\n",
        "if result:\n",
        "    print(\"\\nâœ… System is ready! Run launch_app() to start the application.\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸  Please fix the issues above before running the application.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ AI Textbook Notes Generator (Fixed) v4.0\n",
            "============================================================\n",
            "This notebook application includes:\n",
            "â€¢ Professional PDF generation with styling\n",
            "â€¢ Built-in diagnostics and error handling\n",
            "â€¢ Cross-platform file support\n",
            "â€¢ Automatic quality evaluation and retry logic\n",
            "â€¢ Executive summary generation\n",
            "============================================================\n",
            "ðŸ©º Running System Diagnostics...\n",
            "============================================================\n",
            "âœ… Python version: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
            "âœ… gradio - available\n",
            "âœ… fitz - available\n",
            "âœ… openai - available\n",
            "âœ… pydantic - available\n",
            "âœ… fpdf - available\n",
            "âœ… dotenv - available\n",
            "âœ… asyncio - available\n",
            "âœ… pathlib - available\n",
            "âœ… OpenAI API Key found: sk-proj-...\n",
            "âœ… Google API Key found: AIzaSyDn...\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ All checks passed! System ready to use.\n",
            "ðŸ’¡ Note: Ollama connection will be tested during actual processing.\n",
            "\n",
            "ðŸŒ Starting AI Textbook Notes Generator (Fixed)...\n",
            "ðŸ“ Interface will be available below\n",
            "============================================================\n",
            "âŒ Failed to start application: cannot access local variable 'gr' where it is not associated with a value\n",
            "\n",
            "ðŸ”§ Troubleshooting:\n",
            "â€¢ Ensure all dependencies are installed\n",
            "â€¢ Check if port 7860 is available\n",
            "â€¢ Verify Ollama is running: ollama serve\n",
            "â€¢ Check your API keys in .env file\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "launch_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ Launch Application\n",
        "\n",
        "Run this cell to start the AI Textbook Notes Generator:\n",
        "\n",
        "```python\n",
        "launch_app()\n",
        "```\n",
        "\n",
        "The application will open automatically in your browser!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ AI Textbook Notes Generator (Fixed) v4.0\n",
            "============================================================\n",
            "This notebook application includes:\n",
            "â€¢ Professional PDF generation with styling\n",
            "â€¢ Built-in diagnostics and error handling\n",
            "â€¢ Cross-platform file support\n",
            "â€¢ Automatic quality evaluation and retry logic\n",
            "â€¢ Executive summary generation\n",
            "============================================================\n",
            "ðŸ©º Running System Diagnostics...\n",
            "============================================================\n",
            "âœ… Python version: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
            "âœ… gradio - available\n",
            "âœ… fitz - available\n",
            "âœ… openai - available\n",
            "âœ… pydantic - available\n",
            "âœ… fpdf - available\n",
            "âœ… dotenv - available\n",
            "âœ… asyncio - available\n",
            "âœ… pathlib - available\n",
            "âœ… OpenAI API Key found: sk-proj-...\n",
            "âœ… Google API Key found: AIzaSyDn...\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ All checks passed! System ready to use.\n",
            "ðŸ’¡ Note: Ollama connection will be tested during actual processing.\n",
            "\n",
            "ðŸŒ Starting AI Textbook Notes Generator (Fixed)...\n",
            "ðŸ“ Interface will be available below\n",
            "============================================================\n",
            "âŒ Failed to start application: cannot access local variable 'gr' where it is not associated with a value\n",
            "\n",
            "ðŸ”§ Troubleshooting:\n",
            "â€¢ Ensure all dependencies are installed\n",
            "â€¢ Check if port 7860 is available\n",
            "â€¢ Verify Ollama is running: ollama serve\n",
            "â€¢ Check your API keys in .env file\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Launch the application\n",
        "launch_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“‹ Usage Guide\n",
        "\n",
        "## 1. Setup Requirements\n",
        "```bash\n",
        "# Create .env file with your API keys\n",
        "echo \"OPENAI_API_KEY=your_key_here\" > .env\n",
        "echo \"GOOGLE_API_KEY=your_key_here\" >> .env\n",
        "\n",
        "# Start Ollama (in a separate terminal)\n",
        "ollama serve\n",
        "ollama pull llama3:8b\n",
        "```\n",
        "\n",
        "## 2. How to Use\n",
        "1. **Upload PDF**: Click \"ðŸ“– Upload Your Textbook (PDF)\" and select your PDF file\n",
        "2. **Process**: Click \"ðŸš€ Generate Beautiful Notes\"\n",
        "3. **Monitor**: Watch the progress bar and status updates\n",
        "4. **Download**: Once complete, download your generated PDF notes\n",
        "\n",
        "## 3. What Happens\n",
        "1. **Text Extraction**: PDF text is extracted using PyMuPDF\n",
        "2. **AI Processing**: Text is chunked and processed by Ollama (llama3:8b)\n",
        "3. **Quality Check**: Notes are evaluated by Gemini AI with retry logic\n",
        "4. **Summary**: Executive summary is generated\n",
        "5. **PDF Creation**: Professional PDF with styling and formatting\n",
        "\n",
        "## 4. Features\n",
        "- âœ… Professional PDF generation with title page and styling\n",
        "- âœ… AI-powered note generation (Ollama + llama3:8b)\n",
        "- âœ… Quality evaluation and retry logic (Gemini)\n",
        "- âœ… Executive summary generation\n",
        "- âœ… Real-time progress tracking\n",
        "- âœ… Comprehensive error handling\n",
        "- âœ… Cross-platform compatibility\n",
        "\n",
        "## 5. Troubleshooting\n",
        "**Common Issues:**\n",
        "- **Ollama not running**: Start with `ollama serve`\n",
        "- **API keys missing**: Add them to your .env file\n",
        "- **Port busy**: Close other applications using port 7860\n",
        "- **Large PDF**: Keep files under 50MB for best performance\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
