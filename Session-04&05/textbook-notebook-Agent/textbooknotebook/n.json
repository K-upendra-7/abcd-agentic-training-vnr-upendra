{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ñ AI Textbook Notes Generator (Complete)\n",
                "\n",
                "This notebook contains the complete, corrected code for the AI Textbook Notes Generator application.\n",
                "\n",
                "**Key fixes applied:**\n",
                "\n",
                "* **Gemini Model:** Updated `gemini-2.5-flash` to the correct `gemini-1.5-flash-latest`.\n",
                "* **Gradio Logic:** Fixed the `submit_btn.click` event to correctly route success/error messages to the status box and the generated file to the file output.\n",
                "* **PDF Styling:** Cleaned up a redundant code block in the `StyledPDF` class.\n",
                "* **Gradio Launch:** Removed deprecated parameters from `interface.launch()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import gradio as gr\n",
                "import textwrap\n",
                "import asyncio\n",
                "import fitz  # PyMuPDF\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "from openai import AsyncOpenAI\n",
                "from pydantic import BaseModel\n",
                "from fpdf import FPDF\n",
                "from datetime import datetime\n",
                "from pathlib import Path\n",
                "\n",
                "# Version info\n",
                "VERSION = \"4.0.1\"\n",
                "APP_NAME = \"AI Textbook Notes Generator (Complete)\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ENVIRONMENT SETUP & VALIDATION\n",
                "# =============================================================================\n",
                "\n",
                "def load_environment():\n",
                "    \"\"\"Load and validate environment configuration\"\"\"\n",
                "    load_dotenv(override=True)\n",
                "    \n",
                "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
                "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
                "    \n",
                "    if not openai_api_key:\n",
                "        print(\"‚ùå OPENAI_API_KEY not found in environment\")\n",
                "        return False, None, None\n",
                "    \n",
                "    if not google_api_key:\n",
                "        print(\"‚ùå GOOGLE_API_KEY not found in environment\")  \n",
                "        return False, None, None\n",
                "    \n",
                "    print(f\"‚úÖ OpenAI API Key found: {openai_api_key[:8]}...\")\n",
                "    print(f\"‚úÖ Google API Key found: {google_api_key[:8]}...\")\n",
                "    \n",
                "    return True, openai_api_key, google_api_key"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# API CLIENTS SETUP\n",
                "# =============================================================================\n",
                "\n",
                "def setup_api_clients(google_api_key):\n",
                "    \"\"\"Setup Ollama and Gemini API clients\"\"\"\n",
                "    try:\n",
                "        # Ollama client for note generation\n",
                "        ollama_client = AsyncOpenAI(\n",
                "            base_url=\"http://localhost:11434/v1\",\n",
                "            api_key=\"ollama\"\n",
                "        )\n",
                "        \n",
                "        # Gemini client for evaluation and summary\n",
                "        gemini_client = AsyncOpenAI(\n",
                "            api_key=google_api_key,\n",
                "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
                "        )\n",
                "        \n",
                "        return ollama_client, gemini_client\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Failed to setup API clients: {e}\")\n",
                "        return None, None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DATA MODELS\n",
                "# =============================================================================\n",
                "\n",
                "class Evaluation(BaseModel):\n",
                "    \"\"\"Evaluation model for note quality assessment\"\"\"\n",
                "    is_acceptable: bool\n",
                "    feedback: str\n",
                "    clarity_score: int  # Score from 1-5\n",
                "    accuracy_score: int # Score from 1-5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TEXT PROCESSING UTILITIES\n",
                "# =============================================================================\n",
                "\n",
                "def chunk_text(text: str, max_chars: int = 2500):\n",
                "    \"\"\"Split text into manageable chunks for processing\"\"\"\n",
                "    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)\n",
                "\n",
                "def validate_file_upload(file):\n",
                "    \"\"\"Validate uploaded file and return appropriate path or error\"\"\"\n",
                "    if file is None:\n",
                "        return None, \"‚ùå No file uploaded. Please select a PDF file.\"\n",
                "    \n",
                "    try:\n",
                "        # Handle both file object and string path\n",
                "        if hasattr(file, 'name'):\n",
                "            file_path = file.name\n",
                "        else:\n",
                "            file_path = str(file)\n",
                "            \n",
                "        # Check file existence\n",
                "        if not os.path.exists(file_path):\n",
                "            return None, f\"‚ùå File not found: {file_path}\"\n",
                "            \n",
                "        # Check file extension\n",
                "        if not file_path.lower().endswith('.pdf'):\n",
                "            return None, f\"‚ùå File must be a PDF. Received: {file_path}\"\n",
                "            \n",
                "        # Check file size (optional)\n",
                "        try:\n",
                "            file_size = os.path.getsize(file_path)\n",
                "            if file_size == 0:\n",
                "                return None, \"‚ùå File is empty.\"\n",
                "            if file_size > 50 * 1024 * 1024:  # 50MB limit\n",
                "                return None, \"‚ùå File too large. Maximum size is 50MB.\"\n",
                "        except OSError:\n",
                "            pass\n",
                "            \n",
                "        return file_path, None\n",
                "        \n",
                "    except Exception as e:\n",
                "        return None, f\"‚ùå Error accessing file: {e}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# PDF TEXT EXTRACTION\n",
                "# =============================================================================\n",
                "\n",
                "async def extract_text_from_pdf(file_path, progress_callback=None):\n",
                "    \"\"\"Extract text content from PDF file using PyMuPDF\"\"\"\n",
                "    if progress_callback:\n",
                "        progress_callback(0.1, \"Initializing PDF extraction...\")\n",
                "    \n",
                "    try:\n",
                "        doc = fitz.open(file_path)\n",
                "        num_pages = len(doc)\n",
                "        \n",
                "        if num_pages == 0:\n",
                "            return None, \"‚ùå PDF appears to be empty or corrupted.\"\n",
                "        \n",
                "        full_text = \"\"\n",
                "        for i, page in enumerate(doc):\n",
                "            if progress_callback:\n",
                "                progress = 0.1 + (i / num_pages) * 0.3  # 10% to 40% for extraction\n",
                "                progress_callback(progress, f\"Extracting from Page {i + 1}/{num_pages}\")\n",
                "            \n",
                "            page_text = page.get_text()\n",
                "            if page_text.strip():\n",
                "                full_text += page_text + \"\\n\"\n",
                "        \n",
                "        doc.close()\n",
                "        \n",
                "        if not full_text.strip():\n",
                "            return None, \"‚ùå No readable text found in PDF. Ensure the PDF contains extractable text.\"\n",
                "        \n",
                "        if progress_callback:\n",
                "            progress_callback(0.4, f\"Text extraction complete. {len(full_text)} characters found.\")\n",
                "            \n",
                "        return full_text, None\n",
                "        \n",
                "    except Exception as e:\n",
                "        return None, f\"‚ùå Error extracting text from PDF: {e}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# AI NOTE GENERATION\n",
                "# =============================================================================\n",
                "\n",
                "async def generate_notes_with_retry(ollama_client, text_chunk: str, retries: int = 2, feedback: str = \"\"):\n",
                "    \"\"\"Generate structured notes with self-correction\"\"\"\n",
                "    system_prompt = (\n",
                "        \"You are an expert academic assistant. \"\n",
                "        \"Read the provided text and produce well-organized, clear Markdown notes. \"\n",
                "        \"Focus on key concepts, definitions, and main ideas. \"\n",
                "        \"Keep the language simple but precise. \"\n",
                "        \"Structure the notes with clear headings and bullet points.\"\n",
                "    )\n",
                "\n",
                "    if feedback:\n",
                "        user_prompt = (\n",
                "            f\"The previous notes were not acceptable. Improve them using this feedback:\\n\"\n",
                "            f\"{feedback}\\n\\nOriginal Text:\\n{text_chunk}\"\n",
                "        )\n",
                "    else:\n",
                "        user_prompt = f\"Generate concise academic notes for the following text:\\n{text_chunk}\"\n",
                "\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": system_prompt},\n",
                "        {\"role\": \"user\", \"content\": user_prompt},\n",
                "    ]\n",
                "\n",
                "    try:\n",
                "        response = await ollama_client.chat.completions.create(\n",
                "            model=\"llama3:8b\",\n",
                "            messages=messages,\n",
                "            timeout=60  # 1 minute timeout\n",
                "        )\n",
                "        notes = response.choices[0].message.content\n",
                "        return notes\n",
                "        \n",
                "    except asyncio.TimeoutError:\n",
                "        return f\"Error: Generation timeout for this chunk.\"\n",
                "    except Exception as e:\n",
                "        return f\"Error generating notes: {e}\"\n",
                "\n",
                "async def evaluate_notes_quality(gemini_client, text_chunk: str, notes: str) -> Evaluation:\n",
                "    \"\"\"Evaluate generated notes using Gemini\"\"\"\n",
                "    prompt = (\n",
                "        \"You are a strict quality assurance evaluator. Assess the provided notes \"\n",
                "        \"based on their accuracy (do they match the original text?), \"\n",
                "        \"clarity (are they easy to understand?), and \"\n",
                "        \"completeness (did they miss key concepts from the text?). \"\n",
                "        \"Return a JSON object with four keys only:\\n\"\n",
                "        \"1. is_acceptable (boolean): True if the notes are high quality, False otherwise.\\n\"\n",
                "        \"2. feedback (string): Specific, actionable feedback for improvement.\\n\"\n",
                "        \"3. clarity_score (int): A score from 1 (unclear) to 5 (very clear).\\n\"\n",
                "        \"4. accuracy_score (int): A score from 1 (inaccurate) to 5 (very accurate).\\n\\n\"\n",
                "        f\"--- Original Text ---\\n{text_chunk}\\n\\n\"\n",
                "        f\"--- Notes ---\\n{notes}\"\n",
                "    )\n",
                "\n",
                "    try:\n",
                "        response = await gemini_client.chat.completions.create(\n",
                "            model=\"gemini-1.5-flash-latest\",  # <<< FIX: Was gemini-2.5-flash\n",
                "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "            response_format={\"type\": \"json_object\"},\n",
                "            timeout=30  # 30 second timeout\n",
                "        )\n",
                "\n",
                "        data = json.loads(response.choices[0].message.content)\n",
                "        return Evaluation(**data)\n",
                "\n",
                "    except asyncio.TimeoutError:\n",
                "        print(\"‚ö†Ô∏è  Note evaluation timeout - accepting current quality\")\n",
                "        return Evaluation(\n",
                "            is_acceptable=True,\n",
                "            feedback=\"Evaluation timeout - accepted current quality\",\n",
                "            clarity_score=4,\n",
                "            accuracy_score=4\n",
                "        )\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è  Note evaluation error: {e}\")\n",
                "        return Evaluation(\n",
                "            is_acceptable=True,\n",
                "            feedback=f\"Evaluation failed: {e}\",\n",
                "            clarity_score=4,\n",
                "            accuracy_score=4\n",
                "        )\n",
                "\n",
                "async def generate_final_summary(gemini_client, all_notes: str):\n",
                "    \"\"\"Generate executive summary using Gemini\"\"\"\n",
                "    prompt = (\n",
                "        \"You are an expert academic summarizer. \"\n",
                "        \"Read all the provided notes (which were generated from a textbook) \"\n",
                "        \"and generate a concise, high-level executive summary. \"\n",
                "        \"This summary should capture the main themes, key takeaways, and \"\n",
                "        \"overall structure of the content. Output in clean Markdown.\"\n",
                "        f\"\\n\\n--- All Notes ---\\n{all_notes}\"\n",
                "    )\n",
                "    \n",
                "    try:\n",
                "        response = await gemini_client.chat.completions.create(\n",
                "            model=\"gemini-1.5-flash-latest\",  # <<< FIX: Was gemini-2.5-flash\n",
                "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "            timeout=45  # 45 second timeout\n",
                "        )\n",
                "        return response.choices[0].message.content\n",
                "    except asyncio.TimeoutError:\n",
                "        return \"Executive Summary (Generation timeout - providing basic summary). This textbook covers important concepts and principles that form the foundation of the subject matter.\"\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è  Executive summary error: {e}\")\n",
                "        return f\"Executive Summary (Generation failed: {e}). This appears to be an academic text covering various important concepts.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# PDF CREATION WITH PROFESSIONAL STYLING\n",
                "# =============================================================================\n",
                "\n",
                "class StyledPDF(FPDF):\n",
                "    \"\"\"Enhanced PDF class with professional styling\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.set_auto_page_break(auto=True, margin=15)\n",
                "        \n",
                "    def header(self):\n",
                "        \"\"\"Header with page number\"\"\"\n",
                "        self.set_font('Arial', 'I', 8)\n",
                "        self.set_text_color(128, 128, 128)\n",
                "        self.cell(0, 10, f'{APP_NAME}', 0, 0, 'C')\n",
                "        self.ln(5)\n",
                "        \n",
                "    def footer(self):\n",
                "        \"\"\"Footer with page numbers\"\"\"\n",
                "        self.set_y(-15)\n",
                "        self.set_font('Arial', 'I', 8)\n",
                "        self.set_text_color(128, 128, 128)\n",
                "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
                "        \n",
                "    def create_title_page(self, title: str):\n",
                "        \"\"\"Create a professional title page\"\"\"\n",
                "        self.add_page()\n",
                "        \n",
                "        # Main title\n",
                "        self.set_font('Arial', 'B', 24)\n",
                "        self.set_text_color(0, 51, 102)\n",
                "        self.ln(60)\n",
                "        \n",
                "        # Center the title\n",
                "        title_lines = self.split_text(title, 180)\n",
                "        for line in title_lines:\n",
                "            self.cell(0, 15, line, 0, 1, 'C')\n",
                "        \n",
                "        self.ln(20)\n",
                "        \n",
                "        # Subtitle\n",
                "        self.set_font('Arial', 'I', 14)\n",
                "        self.set_text_color(102, 102, 102)\n",
                "        subtitle_lines = self.split_text(\"Generated by AI Textbook Notes Generator\", 180)\n",
                "        for line in subtitle_lines:\n",
                "            self.cell(0, 10, line, 0, 1, 'C')\n",
                "        \n",
                "        self.ln(20)\n",
                "        \n",
                "        # Generation info\n",
                "        self.set_font('Arial', '', 12)\n",
                "        self.set_text_color(128, 128, 128)\n",
                "        date_str = datetime.now().strftime(\"%B %d, %Y\")\n",
                "        info_text = f\"Generated on {date_str}\"\n",
                "        self.cell(0, 8, info_text, 0, 1, 'C')\n",
                "        \n",
                "        self.ln(40)\n",
                "        \n",
                "        # Decorative border\n",
                "        self.set_line_width(2)\n",
                "        self.set_draw_color(0, 51, 102)\n",
                "        self.line(15, self.get_y(), 195, self.get_y())\n",
                "        \n",
                "    def split_text(self, text, max_width):\n",
                "        \"\"\"Split text to fit within max_width\"\"\"\n",
                "        words = text.split()\n",
                "        lines = []\n",
                "        current_line = \"\"\n",
                "        \n",
                "        for word in words:\n",
                "            test_line = current_line + (\" \" if current_line else \"\") + word\n",
                "            if self.get_string_width(test_line) <= max_width:\n",
                "                current_line = test_line\n",
                "            else:\n",
                "                if current_line:\n",
                "                    lines.append(current_line)\n",
                "                current_line = word\n",
                "                \n",
                "        if current_line:\n",
                "            lines.append(current_line)\n",
                "            \n",
                "        return lines\n",
                "\n",
                "    def add_section_header(self, title: str):\n",
                "        \"\"\"Add a styled section header\"\"\"\n",
                "        self.ln(10)\n",
                "        self.set_font('Arial', 'B', 16)\n",
                "        self.set_text_color(0, 51, 102)\n",
                "        self.cell(0, 12, title, 0, 1, 'L')\n",
                "        \n",
                "        # Decorative underline\n",
                "        self.set_line_width(0.8)\n",
                "        self.set_draw_color(0, 51, 102)\n",
                "        self.line(15, self.get_y(), 100, self.get_y())\n",
                "        self.ln(8)\n",
                "\n",
                "    def add_content_line(self, text: str, indent: int = 0):\n",
                "        \"\"\"Add a line of content with proper formatting\"\"\"\n",
                "        self.set_font('Arial', '', 11)\n",
                "        self.set_text_color(0, 0, 0)\n",
                "        \n",
                "        # Handle bullet points\n",
                "        if text.strip().startswith('‚Ä¢') or text.strip().startswith('-'):\n",
                "            bullet = text.strip()[0]\n",
                "            content = text.strip()[1:].strip()\n",
                "            \n",
                "            if indent > 0:\n",
                "                self.cell(indent, 6, '', 0, 0, 'L')\n",
                "            self.cell(10, 6, bullet, 0, 0, 'L')\n",
                "            \n",
                "            lines = self.split_text(content, 180 - indent - 10)\n",
                "            if lines:\n",
                "                self.cell(0, 6, lines[0], 0, 1, 'L')\n",
                "                for line in lines[1:]:\n",
                "                    if indent > 0:\n",
                "                        self.cell(indent, 6, '', 0, 0, 'L')\n",
                "                    self.cell(10, 6, '', 0, 0, 'L')\n",
                "                    self.cell(0, 6, line, 0, 1, 'L')\n",
                "        else:\n",
                "            # <<< FIX: Simplified this logic block to remove redundancy\n",
                "            # Regular text with word wrapping\n",
                "            lines = self.split_text(text, 180 - indent)\n",
                "            if lines:\n",
                "                # Print first line with indent\n",
                "                if indent > 0:\n",
                "                    self.cell(indent, 6, '', 0, 0, 'L')\n",
                "                self.cell(0, 6, lines[0], 0, 1, 'L')\n",
                "                \n",
                "                # Print subsequent lines with same indent\n",
                "                for line in lines[1:]:\n",
                "                    if indent > 0:\n",
                "                        self.cell(indent, 6, '', 0, 0, 'L')\n",
                "                    self.cell(0, 6, line, 0, 1, 'L')\n",
                "            # <<< END FIX\n",
                "\n",
                "    def process_markdown(self, markdown_content: str):\n",
                "        \"\"\"Process markdown content and add to PDF\"\"\"\n",
                "        lines = markdown_content.split('\\n')\n",
                "        \n",
                "        for line in lines:\n",
                "            line = line.strip()\n",
                "            \n",
                "            if not line:\n",
                "                # Empty line\n",
                "                self.ln(4)\n",
                "                continue\n",
                "                \n",
                "            if line.startswith('# '):\n",
                "                # Main heading\n",
                "                title = line[2:].strip()\n",
                "                self.add_section_header(title)\n",
                "                \n",
                "            elif line.startswith('## '):\n",
                "                # Subheading\n",
                "                title = line[3:].strip()\n",
                "                self.set_font('Arial', 'B', 14)\n",
                "                self.set_text_color(51, 102, 153)\n",
                "                self.ln(5)\n",
                "                self.cell(0, 10, title, 0, 1, 'L')\n",
                "                self.set_line_width(0.5)\n",
                "                self.set_draw_color(200, 200, 200)\n",
                "                self.line(15, self.get_y(), 100, self.get_y())\n",
                "                self.ln(8)\n",
                "                \n",
                "            elif line.startswith('### '):\n",
                "                # Sub-subheading\n",
                "                title = line[4:].strip()\n",
                "                self.set_font('Arial', 'B', 12)\n",
                "                self.set_text_color(102, 102, 153)\n",
                "                self.ln(3)\n",
                "                self.cell(0, 8, title, 0, 1, 'L')\n",
                "                self.ln(3)\n",
                "                \n",
                "            elif line.startswith('- ') or line.startswith('‚Ä¢ '):\n",
                "                # Bullet point\n",
                "                content = line[2:].strip()\n",
                "                self.add_content_line('‚Ä¢ ' + content, indent=15)\n",
                "                \n",
                "            else:\n",
                "                # Regular paragraph\n",
                "                if line:\n",
                "                    self.add_content_line(line)\n",
                "\n",
                "def create_styled_pdf(notes_markdown: str, source_filename: str) -> tuple[str, str]:\n",
                "    \"\"\"Create a beautifully formatted PDF from notes\"\"\"\n",
                "    try:\n",
                "        # Generate output filename\n",
                "        base_name = os.path.splitext(os.path.basename(source_filename))[0]\n",
                "        output_filename = f\"{base_name}_ai_notes.pdf\"\n",
                "        \n",
                "        # Create PDF\n",
                "        pdf = StyledPDF()\n",
                "        \n",
                "        # Title\n",
                "        title = base_name.replace('_', ' ').title()\n",
                "        pdf.create_title_page(title)\n",
                "        \n",
                "        # Process content\n",
                "        pdf.process_markdown(notes_markdown)\n",
                "        \n",
                "        # Save\n",
                "        pdf.output(output_filename)\n",
                "        \n",
                "        print(f\"‚úÖ PDF created successfully: {output_filename}\")\n",
                "        return output_filename, None\n",
                "        \n",
                "    except Exception as e:\n",
                "        error_msg = f\"‚ùå Error creating PDF: {e}\"\n",
                "        print(error_msg)\n",
                "        return None, error_msg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MAIN PROCESSING PIPELINE\n",
                "# =============================================================================\n",
                "\n",
                "async def process_textbook_complete(file, progress_callback=None):\n",
                "    \"\"\"Complete processing pipeline from PDF upload to formatted notes\"\"\"\n",
                "    \n",
                "    # Step 1: File validation\n",
                "    if progress_callback:\n",
                "        progress_callback(0.05, \"Validating file...\")\n",
                "    \n",
                "    file_path, error = validate_file_upload(file)\n",
                "    if error:\n",
                "        return None, error\n",
                "    if progress_callback:\n",
                "        progress_callback(0.1, \"File validated successfully\")\n",
                "    \n",
                "    # Step 2: Environment setup\n",
                "    env_ok, openai_key, google_key = load_environment()\n",
                "    if not env_ok:\n",
                "        return None, \"Environment setup failed. Please check your .env file.\"\n",
                "    \n",
                "    # Step 3: API client setup\n",
                "    if progress_callback:\n",
                "        progress_callback(0.15, \"Setting up API clients...\")\n",
                "    \n",
                "    ollama_client, gemini_client = setup_api_clients(google_key)\n",
                "    if not ollama_client or not gemini_client:\n",
                "        return None, \"Failed to setup API clients. Please check your internet connection and API keys.\"\n",
                "    if progress_callback:\n",
                "        progress_callback(0.2, \"API clients ready\")\n",
                "    \n",
                "    # Step 4: Extract text from PDF\n",
                "    full_text, error = await extract_text_from_pdf(file_path, progress_callback)\n",
                "    if error:\n",
                "        return None, error\n",
                "    \n",
                "    if progress_callback:\n",
                "        progress_callback(0.4, \"Text extraction complete\")\n",
                "    \n",
                "    # Step 5: Chunk text and generate notes\n",
                "    if progress_callback:\n",
                "        progress_callback(0.45, \"Starting note generation...\")\n",
                "    \n",
                "    chunks = chunk_text(full_text)\n",
                "    all_notes = []\n",
                "    num_chunks = len(chunks)\n",
                "    \n",
                "    if progress_callback:\n",
                "        progress_callback(0.5, f\"Processing {num_chunks} text chunks...\")\n",
                "    \n",
                "    for i, chunk in enumerate(chunks):\n",
                "        if progress_callback:\n",
                "            progress = 0.5 + (i / num_chunks) * 0.3  # 50% to 80%\n",
                "            progress_callback(progress, f\"Generating notes - Chunk {i + 1}/{num_chunks}\")\n",
                "        \n",
                "        try:\n",
                "            # Generate notes with retry logic\n",
                "            notes_chunk = await generate_notes_with_retry(ollama_client, chunk)\n",
                "            \n",
                "            # Evaluate quality\n",
                "            evaluation = await evaluate_notes_quality(gemini_client, chunk, notes_chunk)\n",
                "            \n",
                "            # Retry if necessary\n",
                "            if not evaluation.is_acceptable or (evaluation.clarity_score < 3 or evaluation.accuracy_score < 3):\n",
                "                print(f\"üîÑ Retrying chunk {i + 1} with feedback: {evaluation.feedback}\")\n",
                "                notes_chunk = await generate_notes_with_retry(ollama_client, chunk, retries=1, feedback=evaluation.feedback)\n",
                "            \n",
                "            all_notes.append(notes_chunk)\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"‚ö†Ô∏è  Error processing chunk {i + 1}: {e}\")\n",
                "            all_notes.append(f\"[Note: Error processing this section - {str(e)}]\")\n",
                "    \n",
                "    if progress_callback:\n",
                "        progress_callback(0.8, \"Note generation complete\")\n",
                "    \n",
                "    # Step 6: Generate executive summary\n",
                "    if progress_callback:\n",
                "        progress_callback(0.82, \"Generating executive summary...\")\n",
                "    \n",
                "    combined_notes = \"\\n\\n---\\n\\n\".join(all_notes)\n",
                "    final_summary = await generate_final_summary(gemini_client, combined_notes)\n",
                "    \n",
                "    if progress_callback:\n",
                "        progress_callback(0.88, \"Executive summary complete\")\n",
                "    \n",
                "    # Step 7: Create final markdown\n",
                "    final_markdown = f\"# Executive Summary\\n\\n{final_summary}\\n\\n---\\n\\n# Detailed Notes\\n\\n{combined_notes}\"\n",
                "    \n",
                "    # Step 8: Create styled PDF\n",
                "    if progress_callback:\n",
                "        progress_callback(0.9, \"Creating beautiful PDF...\")\n",
                "    \n",
                "    pdf_path, error = create_styled_pdf(final_markdown, file_path)\n",
                "    if error:\n",
                "        return None, error\n",
                "    \n",
                "    if progress_callback:\n",
                "        progress_callback(1.0, \"Processing complete!\")\n",
                "    \n",
                "    return pdf_path, None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# GRADIO INTERFACE\n",
                "# =============================================================================\n",
                "\n",
                "def create_interface():\n",
                "    \"\"\"Create the Gradio interface\"\"\"\n",
                "    \n",
                "    # <<< FIX: Reworked this function to return (file, status) for the outputs\n",
                "    def process_with_progress(file, progress=gr.Progress(track_tqdm=True)):\n",
                "        \"\"\"Wrapper function with progress tracking\"\"\"\n",
                "        def progress_callback(value, desc):\n",
                "            progress(value, desc=desc)\n",
                "            \n",
                "        # Run the async function\n",
                "        pdf_path, error = asyncio.run(process_textbook_complete(file, progress_callback))\n",
                "        \n",
                "        if error:\n",
                "            # Return None for the file output, and the error for the status\n",
                "            print(f\"Returning error to UI: {error}\")\n",
                "            return None, f\"‚ùå Error: {error}\"\n",
                "        else:\n",
                "            # Return the path for the file output, and success for the status\n",
                "            print(f\"Returning success to UI: {pdf_path}\")\n",
                "            return pdf_path, \"‚úÖ Processing complete! Download your notes.\"\n",
                "    \n",
                "    # Custom CSS for better appearance\n",
                "    css = \"\"\"\n",
                "    .gradio-container { \n",
                "        max-width: 900px !important; \n",
                "        margin: auto !important; \n",
                "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
                "    }\n",
                "    .title { \n",
                "        text-align: center; \n",
                "        color: #003366; \n",
                "        font-size: 32px; \n",
                "        margin-bottom: 15px;\n",
                "        font-weight: bold;\n",
                "    }\n",
                "    .description { \n",
                "        text-align: center; \n",
                "        color: #666; \n",
                "        margin-bottom: 25px;\n",
                "        font-size: 16px;\n",
                "    }\n",
                "    .status-info {\n",
                "        background-color: #f8f9fa;\n",
                "        border: 1px solid #dee2e6;\n",
                "        border-radius: 8px;\n",
                "        padding: 15px;\n",
                "        margin: 10px 0;\n",
                "    }\n",
                "    \"\"\"\n",
                "    \n",
                "    with gr.Blocks(css=css) as interface:\n",
                "        gr.HTML(f\"\"\"\n",
                "        <div class=\"title\">{APP_NAME} v{VERSION}</div>\n",
                "        <div class=\"description\">\n",
                "            Transform any textbook PDF into beautifully formatted study notes with executive summary.<br>\n",
                "            Upload your textbook ‚Üí Get professional PDF notes with styling, TOC, and quality evaluation.\n",
                "        </div>\n",
                "        \"\"\"\"\"\"\")\n",
                "        \n",
                "        with gr.Row():\n",
                "            with gr.Column(scale=1):\n",
                "                file_input = gr.File(\n",
                "                    label=\"üìñ Upload Your Textbook (PDF)\", \n",
                "                    file_types=[\".pdf\"],\n",
                "                    info=\"Select a PDF file containing textbook content\"\n",
                "                )\n",
                "                \n",
                "                gr.HTML(\"\"\"\n",
                "                <div class=\"status-info\">\n",
                "                    <strong>üìã Requirements:</strong><br>\n",
                "                    ‚Ä¢ PDF must contain extractable text (not just images)<br>\n",
                "                    ‚Ä¢ File size: Max 50MB<br>\n",
                "                    ‚Ä¢ Ensure Ollama is running with llama3:8b model<br>\n",
                "                    ‚Ä¢ Configure OPENAI_API_KEY and GOOGLE_API_KEY in .env file\n",
                "                </div>\n",
                "                \"\"\"\"\"\"\")\n",
                "                \n",
                "            with gr.Column(scale=1):\n",
                "                output_file = gr.File(\n",
                "                    label=\"üì• Download Generated Notes (.pdf)\", \n",
                "                    info=\"Your beautifully formatted notes will appear here\"\n",
                "                )\n",
                "        \n",
                "        with gr.Row():\n",
                "            submit_btn = gr.Button(\"üöÄ Generate Beautiful Notes\", variant=\"primary\", size=\"lg\")\n",
                "            clear_btn = gr.Button(\"üóëÔ∏è Clear\", variant=\"secondary\")\n",
                "        \n",
                "        # Status display\n",
                "        status_output = gr.Textbox(\n",
                "            label=\"üìä Current Status\", \n",
                "            value=\"Ready to process your textbook\",\n",
                "            interactive=False,\n",
                "            lines=3\n",
                "        )\n",
                "        \n",
                "        # <<< FIX: Reworked click event to use both outputs from the function\n",
                "        submit_btn.click(\n",
                "            fn=process_with_progress,\n",
                "            inputs=[file_input],\n",
                "            outputs=[output_file, status_output], # Send output to file and status\n",
                "            show_progress=\"full\"\n",
                "        )\n",
                "        # <<< FIX: Removed the separate .then() call, as it's now handled above\n",
                "        \n",
                "        # <<< FIX: Clear button now clears the input file as well\n",
                "        clear_btn.click(\n",
                "            fn=lambda: (None, None, \"Ready to process your textbook\"),\n",
                "            outputs=[file_input, output_file, status_output]\n",
                "        )\n",
                "    \n",
                "    return interface"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DIAGNOSTIC FUNCTIONS\n",
                "# =============================================================================\n",
                "\n",
                "async def run_system_diagnostics():\n",
                "    \"\"\"Run comprehensive system diagnostics\"\"\"\n",
                "    print(\"ü©∫ Running System Diagnostics...\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    issues = []\n",
                "    \n",
                "    # Check Python version\n",
                "    print(f\"‚úÖ Python version: {sys.version}\")\n",
                "    \n",
                "    # Check required packages\n",
                "    required_packages = [\n",
                "        'gradio', 'fitz', 'openai', 'pydantic', 'fpdf',\n",
                "        'dotenv', 'asyncio', 'pathlib'\n",
                "    ]\n",
                "    # Note: 'fpdf' is the import name for 'fpdf2' package\n",
                "    \n",
                "    for package in required_packages:\n",
                "        try:\n",
                "            __import__(package)\n",
                "            print(f\"‚úÖ {package} - available\")\n",
                "        except ImportError:\n",
                "            pkg_name = 'PyMuPDF' if package == 'fitz' else 'fpdf2' if package == 'fpdf' else 'python-dotenv' if package == 'dotenv' else package\n",
                "            print(f\"‚ùå {package} - MISSING\")\n",
                "            issues.append(f\"Install {pkg_name}: pip install {pkg_name}\")\n",
                "    \n",
                "    # Check environment\n",
                "    env_ok, openai_key, google_key = load_environment()\n",
                "    if not env_ok:\n",
                "        issues.append(\"Configure OPENAI_API_KEY and GOOGLE_API_KEY in .env file\")\n",
                "    \n",
                "    # Check Ollama\n",
                "    try:\n",
                "        from openai import AsyncOpenAI\n",
                "        ollama_client = AsyncOpenAI(\n",
                "            base_url=\"http://localhost:11434/v1\",\n",
                "            api_key=\"ollama\"\n",
                "        )\n",
                "        \n",
                "        # Test connection\n",
                "        response = await ollama_client.chat.completions.create(\n",
                "            model=\"llama3:8b\",\n",
                "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
                "            max_tokens=5,\n",
                "            timeout=10\n",
                "        )\n",
                "        print(\"‚úÖ Ollama service - running\")\n",
                "        print(\"‚úÖ llama3:8b model - available\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Ollama service - FAILED: {e}\")\n",
                "        issues.append(\"Start Ollama: ollama serve && ollama pull llama3:8b\")\n",
                "    \n",
                "    # Summary\n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    if not issues:\n",
                "        print(\"üéâ All checks passed! System ready to use.\")\n",
                "        return True\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è  Issues found:\")\n",
                "        for i, issue in enumerate(issues, 1):\n",
                "            print(f\"   {i}. {issue}\")\n",
                "        return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MAIN APPLICATION\n",
                "# =============================================================================\n",
                "\n",
                "def main():\n",
                "    \"\"\"Main application entry point\"\"\"\n",
                "    print(f\"üöÄ {APP_NAME} v{VERSION}\")\n",
                "    print(\"=\" * 60)\n",
                "    print(\"This single-file application includes:\")\n",
                "    print(\"‚Ä¢ Professional PDF generation with styling\")\n",
                "    print(\"‚Ä¢ Built-in diagnostics and error handling\")\n",
                "    print(\"‚Ä¢ Cross-platform file support\")\n",
                "    print(\"‚Ä¢ Automatic quality evaluation and retry logic\")\n",
                "    print(\"‚Ä¢ Executive summary generation\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # Run diagnostics first\n",
                "    try:\n",
                "        if not asyncio.run(run_system_diagnostics()):\n",
                "            print(\"\\n‚ùå System not ready. Please fix the issues above before continuing.\")\n",
                "            print(\"üí° You can still run the application - it will show helpful error messages.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è  Diagnostics failed: {e}\")\n",
                "        print(\"üí° Continuing anyway - application will provide runtime checks.\")\n",
                "    \n",
                "    print(f\"\\nüåê Starting {APP_NAME}...\")\n",
                "    print(\"üìç Interface will be available at: http://127.0.0.1:7860\")\n",
                "    print(\"‚èπÔ∏è  Press Ctrl+C to stop\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    try:\n",
                "        # Create and launch interface\n",
                "        interface = create_interface()\n",
                "        interface.launch(\n",
                "            server_name=\"127.0.0.1\", \n",
                "            share=False, \n",
                "            show_error=True\n",
                "            # <<< FIX: Removed quiet=False and quiet_console=False\n",
                "        )\n",
                "        \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\nüëã Shutting down gracefully...\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Failed to start application: {e}\")\n",
                "        print(\"\\nüîß Troubleshooting:\")\n",
                "        print(\"‚Ä¢ Ensure all dependencies are installed (see diagnostics above)\")\n",
                "        print(\"‚Ä¢ Check if port 7860 is available\")\n",
                "        print(\"‚Ä¢ Verify Ollama is running: ollama serve\")\n",
                "        print(\"‚Ä¢ Check your API keys in .env file\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}