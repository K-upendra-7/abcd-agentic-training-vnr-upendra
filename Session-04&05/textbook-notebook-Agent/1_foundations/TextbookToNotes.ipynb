{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595a5d18",
   "metadata": {},
   "source": [
    "AI Agent: Textbook to Notebook Notes Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70970d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3:8b\n",
    "!ollama serve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f755b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "import textwrap\n",
    "import asyncio\n",
    "import markdown_it\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from pypdf import PdfReader\n",
    "from pydantic import BaseModel\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30aa8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41871c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key found, starting with: sk-proj-...\n",
      "Google API Key found, starting with: AIzaSyDn...\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key found, starting with: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not found. Please set it in your .env file.\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key found, starting with: {google_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"Google API Key not found. Please set it in your .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4e81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "gemini_client = AsyncOpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07755414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    \"\"\"Defines evaluator output.\"\"\"\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5273ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_notes(text_chunk: str, retries=2, feedback=\"\"):\n",
    "    \"\"\"\n",
    "    Generate structured notes for a given text chunk using Ollama3:8b.\n",
    "    Self-corrects based on Gemini evaluation feedback.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are an expert academic assistant. \"\n",
    "        \"Read the provided text and produce well-organized, clear Markdown notes. \"\n",
    "        \"Focus on key concepts, definitions, and main ideas. \"\n",
    "        \"Keep the language simple but precise.\"\n",
    "    )\n",
    "\n",
    "    if feedback:\n",
    "        user_prompt = (\n",
    "            f\"The previous notes were not acceptable. Improve them using this feedback:\\n\"\n",
    "            f\"{feedback}\\n\\nOriginal Text:\\n{text_chunk}\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = f\"Generate concise academic notes for the following text:\\n{text_chunk}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = await ollama_client.chat.completions.create(\n",
    "            model=\"llama3:8b\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        notes = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Ollama generation: {e}\")\n",
    "        return f\"Error generating notes: {e}\"\n",
    "\n",
    "    if retries > 0:\n",
    "        evaluation = await evaluate_notes(text_chunk, notes)\n",
    "        if not evaluation.is_acceptable:\n",
    "            print(f\"Evaluation failed. Retrying with feedback: {evaluation.feedback}\")\n",
    "            return await generate_notes(text_chunk, retries - 1, evaluation.feedback)\n",
    "        else:\n",
    "            print(\"Evaluation passed.\")\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81654b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED: Changed the model name to one compatible with the API endpoint\n",
    "async def evaluate_notes(text_chunk: str, notes: str) -> Evaluation:\n",
    "    \"\"\"\n",
    "    Evaluates generated notes using Gemini API for accuracy, clarity, and coverage.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are a quality assurance evaluator. Assess the provided notes \"\n",
    "        \"based on their accuracy, clarity, and completeness. \"\n",
    "        \"Return a JSON object with two keys only:\\n\"\n",
    "        \"1. is_acceptable (boolean)\\n\"\n",
    "        \"2. feedback (string)\\n\\n\"\n",
    "        f\"--- Original Text ---\\n{text_chunk}\\n\\n\"\n",
    "        f\"--- Notes ---\\n{notes}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = await gemini_client.chat.completions.create(\n",
    "            # MODIFICATION IS ON THIS LINE\n",
    "            model=\"gemini-flash2.5\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "\n",
    "        data = json.loads(response.choices[0].message.content)\n",
    "        return Evaluation(**data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Gemini evaluation error: {e}\")\n",
    "        return Evaluation(is_acceptable=True, feedback=f\"Evaluation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767f08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars: int = 2500):\n",
    "    \"\"\"Splits long text into smaller chunks for better processing.\"\"\"\n",
    "    return textwrap.wrap(text, width=max_chars, break_long_words=False, replace_whitespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e6b7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_file(notes_markdown: str, source_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a PDF file from the generated Markdown notes using FPDF2.\n",
    "    \"\"\"\n",
    "    title = os.path.splitext(os.path.basename(source_filename))[0].replace('_', ' ').title()\n",
    "    output_filename = f\"{os.path.splitext(source_filename)[0]}_notes.pdf\"\n",
    "    \n",
    "    # NEW: fpdf2 implementation starts here\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    \n",
    "    # Add a title to the PDF\n",
    "    pdf.set_font(\"Arial\", \"B\", 18)\n",
    "    pdf.cell(0, 10, f\"Notes for {title}\", 0, 1, \"C\")\n",
    "    pdf.ln(10) # Add a little space after the title\n",
    "\n",
    "    # Set the font for the main content\n",
    "    # Note: Default fonts have limited character support.\n",
    "    # For full Unicode, you might need to add a custom font like DejaVu.\n",
    "    pdf.set_font(\"Arial\", \"\", 11)\n",
    "    \n",
    "    try:\n",
    "        # Use the experimental write_markdown feature from fpdf2\n",
    "        # This directly converts the Markdown string into the PDF\n",
    "        pdf.write_markdown(notes_markdown)\n",
    "        \n",
    "        pdf.output(output_filename)\n",
    "        print(f\"PDF created successfully: {output_filename}\")\n",
    "        return output_filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating PDF with fpdf2: {e}\")\n",
    "        # Fallback to saving as a markdown file if PDF generation fails\n",
    "        md_filename = f\"{os.path.splitext(source_filename)[0]}_notes.md\"\n",
    "        with open(md_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# Notes for {title}\\n\\n{notes_markdown}\")\n",
    "        print(f\"As a fallback, Markdown file saved: {md_filename}\")\n",
    "        return md_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f509c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_textbook(file, progress=gr.Progress()):\n",
    "    \"\"\"\n",
    "    Main orchestrator function. Extracts all text from the PDF, generates\n",
    "    a single cohesive set of notes, and saves it as a PDF.\n",
    "    \"\"\"\n",
    "    if file is None:\n",
    "        return None\n",
    "\n",
    "    pdf_file_path = file.name\n",
    "    reader = PdfReader(pdf_file_path)\n",
    "    num_pages = len(reader.pages)\n",
    "    \n",
    "    print(f\"Extracting text from {num_pages} pages...\")\n",
    "    progress(0, desc=\"Step 1/3: Extracting Text...\")\n",
    "    full_text = \"\"\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        progress((i + 1) / num_pages, desc=f\"Extracting from Page {i + 1}/{num_pages}\")\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            full_text += page_text + \"\\n\"\n",
    "\n",
    "    if not full_text.strip():\n",
    "        print(\"No text could be extracted from the PDF.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Text extraction complete. Total characters: {len(full_text)}\")\n",
    "    \n",
    "    chunks = chunk_text(full_text)\n",
    "    num_chunks = len(chunks)\n",
    "    all_notes = []\n",
    "    \n",
    "    print(f\"Generating notes from {num_chunks} text chunks...\")\n",
    "    progress(0, desc=\"Step 2/3: Generating Notes...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        progress((i + 1) / num_chunks, desc=f\"Processing Chunk {i + 1}/{num_chunks}\")\n",
    "        notes_chunk = await generate_notes(chunk)\n",
    "        all_notes.append(notes_chunk)\n",
    "        \n",
    "    combined_notes = \"\\n\\n---\\n\\n\".join(all_notes)\n",
    "\n",
    "    progress(1, desc=\"Step 3/3: Creating PDF...\")\n",
    "    pdf_path = create_pdf_file(combined_notes, pdf_file_path)\n",
    "    return pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399ef01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_notes_interface(file, progress=gr.Progress(track_tqdm=True)):\n",
    "    if file is not None:\n",
    "        return await process_textbook(file, progress)\n",
    "    return \"Please upload a textbook to begin.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76da59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from 37 pages...\n",
      "Text extraction complete. Total characters: 50951\n",
      "Generating notes from 21 text chunks...\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "⚠️ Gemini evaluation error: Error code: 404 - [{'error': {'code': 404, 'message': 'models/gemini-pro is not found for API version v1main, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}]\n",
      "Evaluation passed.\n",
      "Error creating PDF with fpdf2: 'FPDF' object has no attribute 'write_markdown'\n",
      "As a fallback, Markdown file saved: C:\\Users\\kolla\\AppData\\Local\\Temp\\gradio\\2627a5cfa3bc1a27d8e89dd6869558e5f2c8a0b37b92dcb0a3ba5e78b7190bcd\\the-4-hour-workweek-expanded-and-updated-by-timothy-ferriss_notes.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_17036\\1084223039.py:13: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  pdf.set_font(\"Arial\", \"B\", 18)\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_17036\\1084223039.py:14: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, f\"Notes for {title}\", 0, 1, \"C\")\n",
      "C:\\Users\\kolla\\AppData\\Local\\Temp\\ipykernel_17036\\1084223039.py:20: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  pdf.set_font(\"Arial\", \"\", 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iface = gr.Interface(\n",
    "    fn=create_notes_interface,\n",
    "    inputs=gr.File(label=\"Upload Textbook (PDF)\"),\n",
    "    outputs=gr.File(label=\" Download Generated Notes (.pdf)\"),\n",
    "    title=\"AI Textbook → PDF Notes Generator\",\n",
    "    description=(\n",
    "        \"Upload a textbook in PDF format. The local llama3:8b model generates a cohesive summary \"\n",
    "        \"of the entire book, Gemini API evaluates its quality, and you receive a downloadable PDF.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_name=\"127.0.0.1\", share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c39332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
